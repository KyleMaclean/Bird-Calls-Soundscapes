{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860b4559-c238-4fda-892c-fe509da450ea",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install timm\n",
    "\n",
    "import os\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import pandas as pd\n",
    "import math\n",
    "import time\n",
    "import random\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "from contextlib import contextmanager\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from functools import partial\n",
    "\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam, SGD\n",
    "import torchvision.models as models\n",
    "from torch.nn.parameter import Parameter\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from albumentations import ImageOnlyTransform\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "OUTPUT_DIR = '../output/01_stage1/'\n",
    "if not os.path.exists(OUTPUT_DIR):\n",
    "    os.makedirs(OUTPUT_DIR)\n",
    "\n",
    "\n",
    "class CFG:\n",
    "    print_freq = 100\n",
    "    num_workers = 4\n",
    "    model_name = 'resnext50_32x4d'\n",
    "    dim = (128, 281)\n",
    "    scheduler = 'CosineAnnealingWarmRestarts'\n",
    "    epochs = 10\n",
    "    lr = 1e-4\n",
    "    T_0 = 10  # for CosineAnnealingWarmRestarts\n",
    "    min_lr = 5e-7  # for CosineAnnealingWarmRestarts\n",
    "    batch_size = 32\n",
    "    weight_decay = 1e-6\n",
    "    max_grad_norm = 1000\n",
    "    seed = 42\n",
    "    target_size = 2\n",
    "    target_col = 'hasbird'\n",
    "    n_fold = 5\n",
    "    pretrained = True\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "train = pd.read_csv('../input/ff1010bird-duration7/rich_metadata.csv')\n",
    "train.loc[train['hasbird'] == 0, 'filepath'] = '../input/ff1010bird-duration7/nocall/' + train.query('hasbird==0')[\n",
    "    'filename'] + '.npy'\n",
    "train.loc[train['hasbird'] == 1, 'filepath'] = '../input/ff1010bird-duration7/bird/' + train.query('hasbird==1')[\n",
    "    'filename'] + '.npy'\n",
    "\n",
    "train = train.dropna().reset_index(drop=True)\n",
    "\n",
    "folds = train.copy()\n",
    "Fold = StratifiedKFold(n_splits=CFG.n_fold, shuffle=True, random_state=CFG.seed)\n",
    "for n, (train_index, val_index) in enumerate(Fold.split(folds, folds[CFG.target_col])):\n",
    "    folds.loc[val_index, 'fold'] = int(n)\n",
    "folds['fold'] = folds['fold'].astype(int)\n",
    "print(folds.groupby(['fold', CFG.target_col]).size())\n",
    "\n",
    "\n",
    "def get_score(y_true, y_pred):\n",
    "    return accuracy_score(y_true, y_pred)\n",
    "\n",
    "\n",
    "def get_confusion_matrix(y_true, y_pred):\n",
    "    return confusion_matrix(y_true, y_pred)\n",
    "\n",
    "\n",
    "@contextmanager\n",
    "def timer(name):\n",
    "    t0 = time.time()\n",
    "    LOGGER.info(f'[{name}] start')\n",
    "    yield\n",
    "    LOGGER.info(f'[{name}] done in {time.time() - t0:.0f} s.')\n",
    "\n",
    "\n",
    "def init_logger(log_file=OUTPUT_DIR + 'train.log'):\n",
    "    from logging import getLogger, INFO, FileHandler, Formatter, StreamHandler\n",
    "    logger = getLogger(__name__)\n",
    "    logger.setLevel(INFO)\n",
    "    handler1 = StreamHandler()\n",
    "    handler1.setFormatter(Formatter(\"%(message)s\"))\n",
    "    handler2 = FileHandler(filename=log_file)\n",
    "    handler2.setFormatter(Formatter(\"%(message)s\"))\n",
    "    logger.addHandler(handler1)\n",
    "    logger.addHandler(handler2)\n",
    "    return logger\n",
    "\n",
    "\n",
    "LOGGER = init_logger()\n",
    "\n",
    "\n",
    "def seed_torch(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "\n",
    "seed_torch(seed=CFG.seed)\n",
    "\n",
    "\n",
    "class TrainDataset(Dataset):\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.df = df\n",
    "        self.file_paths = df['filepath'].values\n",
    "        self.labels = df['hasbird'].values\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_name = self.file_paths[idx]\n",
    "        file_path = file_name\n",
    "        image = np.load(file_path)\n",
    "        image = image.transpose(1, 2, 0)\n",
    "        image = np.squeeze(image)\n",
    "        image = np.stack((image,) * 3, -1)\n",
    "        if self.transform:\n",
    "            augmented = self.transform(image=image)\n",
    "            image = augmented['image']\n",
    "        label = torch.tensor(self.labels[idx]).long()\n",
    "        return image, label\n",
    "\n",
    "\n",
    "def get_transforms(*, data):\n",
    "    if data == 'train':\n",
    "        return A.Compose([\n",
    "            A.Resize(CFG.dim[0], CFG.dim[1]),\n",
    "            A.HorizontalFlip(p=0.5),\n",
    "            A.VerticalFlip(p=0.5),\n",
    "            A.augmentations.transforms.JpegCompression(p=0.5),\n",
    "            A.augmentations.transforms.ImageCompression(p=0.5,\n",
    "                                                        compression_type=A.augmentations.transforms.ImageCompression.ImageCompressionType.WEBP),\n",
    "            A.Normalize(\n",
    "                mean=[0.485, 0.456, 0.406],\n",
    "                std=[0.229, 0.224, 0.225],\n",
    "            ),\n",
    "            ToTensorV2(),\n",
    "        ])\n",
    "\n",
    "    elif data == 'valid':\n",
    "        return A.Compose([\n",
    "            A.Resize(CFG.dim[0], CFG.dim[1]),\n",
    "            A.Normalize(\n",
    "                mean=[0.485, 0.456, 0.406],\n",
    "                std=[0.229, 0.224, 0.225],\n",
    "            ),\n",
    "            ToTensorV2(),\n",
    "        ])\n",
    "\n",
    "\n",
    "class CustomResNext(nn.Module):\n",
    "    def __init__(self, model_name='resnext50_32x4d', pretrained=True):\n",
    "        super().__init__()\n",
    "        # self.model = torch.load('../models/resnext50_32x4d_ra-d733960d.pth')\n",
    "        self.model = timm.create_model(model_name, pretrained=pretrained)\n",
    "        n_features = self.model.fc.in_features\n",
    "        self.model.fc = nn.Linear(n_features, CFG.target_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (remain %s)' % (asMinutes(s), asMinutes(rs))\n",
    "\n",
    "\n",
    "def train_fn(train_loader, model, criterion, optimizer, epoch, scheduler, device):\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    scores = AverageMeter()\n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "    start = end = time.time()\n",
    "    global_step = 0\n",
    "    for step, (images, labels) in enumerate(train_loader):\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        batch_size = labels.size(0)\n",
    "        y_preds = model(images)\n",
    "        loss = criterion(y_preds, labels)\n",
    "        # record loss\n",
    "        losses.update(loss.item(), batch_size)\n",
    "        loss.backward()\n",
    "        grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), CFG.max_grad_norm)\n",
    "\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        global_step += 1\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "        if step % CFG.print_freq == 0 or step == (len(train_loader) - 1):\n",
    "            print('Epoch: [{0}][{1}/{2}] '\n",
    "                  'Data {data_time.val:.3f} ({data_time.avg:.3f}) '\n",
    "                  'Elapsed {remain:s} '\n",
    "                  'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n",
    "                  'Grad: {grad_norm:.4f}  '\n",
    "                .format(\n",
    "                epoch + 1, step + 1, len(train_loader), batch_time=batch_time,\n",
    "                data_time=data_time, loss=losses,\n",
    "                remain=timeSince(start, float(step + 1) / len(train_loader)),\n",
    "                grad_norm=grad_norm,\n",
    "            ))\n",
    "    return losses.avg\n",
    "\n",
    "\n",
    "def valid_fn(valid_loader, model, criterion, device):\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    scores = AverageMeter()\n",
    "    # switch to evaluation mode\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    start = end = time.time()\n",
    "    for step, (images, labels) in enumerate(valid_loader):\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        batch_size = labels.size(0)\n",
    "        # compute loss\n",
    "        with torch.no_grad():\n",
    "            y_preds = model(images)\n",
    "        loss = criterion(y_preds, labels)\n",
    "        losses.update(loss.item(), batch_size)\n",
    "        # record accuracy\n",
    "        preds.append(y_preds.softmax(1).to('cpu').numpy())\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "        if step % CFG.print_freq == 0 or step == (len(valid_loader) - 1):\n",
    "            print('EVAL: [{0}/{1}] '\n",
    "                  'Data {data_time.val:.3f} ({data_time.avg:.3f}) '\n",
    "                  'Elapsed {remain:s} '\n",
    "                  'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n",
    "                .format(\n",
    "                step + 1, len(valid_loader), batch_time=batch_time,\n",
    "                data_time=data_time, loss=losses,\n",
    "                remain=timeSince(start, float(step + 1) / len(valid_loader)),\n",
    "            ))\n",
    "    predictions = np.concatenate(preds)\n",
    "    return losses.avg, predictions\n",
    "\n",
    "\n",
    "def inference(model, states, test_loader, device):\n",
    "    model.to(device)\n",
    "    tk0 = tqdm(enumerate(test_loader), total=len(test_loader))\n",
    "    probs = []\n",
    "    for i, (images) in tk0:\n",
    "        images = images.to(device)\n",
    "        avg_preds = []\n",
    "        for state in states:\n",
    "            model.load_state_dict(state['model'])\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                y_preds = model(images)\n",
    "            avg_preds.append(y_preds.softmax(1).to('cpu').numpy())\n",
    "        avg_preds = np.mean(avg_preds, axis=0)\n",
    "        probs.append(avg_preds)\n",
    "    probs = np.concatenate(probs)\n",
    "    return probs\n",
    "\n",
    "\n",
    "def train_loop(train_folds, valid_folds):\n",
    "    LOGGER.info(f\"========== training ==========\")\n",
    "\n",
    "    # ====================================================\n",
    "    # loader\n",
    "    # ====================================================\n",
    "    train_dataset = TrainDataset(train_folds,\n",
    "                                 transform=get_transforms(data='train'))\n",
    "    valid_dataset = TrainDataset(valid_folds,\n",
    "                                 transform=get_transforms(data='valid'))\n",
    "\n",
    "    train_loader = DataLoader(train_dataset,\n",
    "                              batch_size=CFG.batch_size,\n",
    "                              shuffle=False,\n",
    "                              num_workers=CFG.num_workers, pin_memory=True, drop_last=True)\n",
    "    valid_loader = DataLoader(valid_dataset,\n",
    "                              batch_size=CFG.batch_size,\n",
    "                              shuffle=False,\n",
    "                              num_workers=CFG.num_workers, pin_memory=True, drop_last=False)\n",
    "\n",
    "    def get_scheduler(optimizer):\n",
    "        scheduler = CosineAnnealingWarmRestarts(optimizer, T_0=CFG.T_0, T_mult=1, eta_min=CFG.min_lr, last_epoch=-1)\n",
    "        return scheduler\n",
    "\n",
    "    # ====================================================\n",
    "    # model & optimizer\n",
    "    # ====================================================\n",
    "    model = CustomResNext(CFG.model_name, pretrained=True)\n",
    "    model.to(CFG.device)\n",
    "\n",
    "    optimizer = Adam(model.parameters(), lr=CFG.lr, weight_decay=CFG.weight_decay, amsgrad=False)\n",
    "    scheduler = get_scheduler(optimizer)\n",
    "\n",
    "    # ====================================================\n",
    "    # loop\n",
    "    # ====================================================\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    best_score = 0.\n",
    "    best_loss = np.inf\n",
    "\n",
    "    scores = []\n",
    "\n",
    "    for epoch in range(CFG.epochs):\n",
    "\n",
    "        start_time = time.time()\n",
    "\n",
    "        # train\n",
    "        avg_loss = train_fn(train_loader, model, criterion, optimizer, epoch, scheduler, CFG.device)\n",
    "\n",
    "        # eval\n",
    "        avg_val_loss, preds = valid_fn(valid_loader, model, criterion, CFG.device)\n",
    "        valid_labels = valid_folds[CFG.target_col].values\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "        # scoring\n",
    "        score = get_score(valid_labels, preds.argmax(1))\n",
    "\n",
    "        elapsed = time.time() - start_time\n",
    "\n",
    "        LOGGER.info(\n",
    "            f'Epoch {epoch + 1} - avg_train_loss: {avg_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  time: {elapsed:.0f}s')\n",
    "        LOGGER.info(f'Epoch {epoch + 1} - Accuracy: {score}')\n",
    "\n",
    "        scores.append(score)\n",
    "\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            LOGGER.info(f'Epoch {epoch + 1} - Save Best Score: {best_score:.4f} Model')\n",
    "            torch.save({'model': model.state_dict(),\n",
    "                        'preds': preds},\n",
    "                       OUTPUT_DIR + f'{CFG.model_name}_best.pth')\n",
    "\n",
    "    check_point = torch.load(OUTPUT_DIR + f'{CFG.model_name}_best.pth')\n",
    "    valid_folds[[str(c) for c in range(CFG.target_size)]] = check_point['preds']\n",
    "    valid_folds['preds'] = check_point['preds'].argmax(1)\n",
    "\n",
    "    return valid_folds, scores\n",
    "\n",
    "\n",
    "def main(fold):\n",
    "    def get_result(result_df):\n",
    "        preds = result_df['preds'].values\n",
    "        labels = result_df[CFG.target_col].values\n",
    "        score = get_score(labels, preds)\n",
    "        LOGGER.info(f'Score: {score:<.5f}')\n",
    "\n",
    "    def get_result2(result_df):\n",
    "        preds = result_df['preds'].values\n",
    "        labels = result_df[CFG.target_col].values\n",
    "        matrix = get_confusion_matrix(labels, preds)\n",
    "        print('TN', matrix[0, 0])\n",
    "        print('FP', matrix[0, 1])\n",
    "        print('FN', matrix[1, 0])\n",
    "        print('TP', matrix[1, 1])\n",
    "\n",
    "    # train \n",
    "    train_folds = folds.query(f'fold!={fold}').reset_index(drop=True)\n",
    "    valid_folds = folds.query(f'fold=={fold}').reset_index(drop=False)\n",
    "    oof_df, scores = train_loop(train_folds, valid_folds)\n",
    "    # CV result\n",
    "    LOGGER.info(f\"========== CV ==========\")\n",
    "    get_result(oof_df)\n",
    "    get_result2(oof_df)\n",
    "    # save result\n",
    "    oof_df.to_csv(OUTPUT_DIR + 'oof_df.csv', index=False)\n",
    "    plt.plot([i for i in range(CFG.epochs)], scores)\n",
    "    plt.title('valid score')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac3a464a-6912-48c5-9a53-5d96280b9d91",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import librosa as lb\n",
    "import librosa.display as lbd\n",
    "import soundfile as sf\n",
    "from soundfile import SoundFile\n",
    "import pandas as pd\n",
    "from IPython.display import Audio\n",
    "from pathlib import Path\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "import joblib, json\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "PART_ID = 0  # The start index in the below list, by changing it you will compute mels on another subset\n",
    "PART_INDEXES = [0, 15718, 31436, 47154, 62874]  # The train_set is splitted into 4 subsets\n",
    "\n",
    "SR = 32_000\n",
    "DURATION = 7\n",
    "SEED = 666\n",
    "\n",
    "DATA_ROOT = Path(\"../input/birdclef-2021\")\n",
    "TRAIN_AUDIO_ROOT = Path(\"../input/birdclef-2021/train_short_audio\")\n",
    "TRAIN_AUDIO_IMAGES_SAVE_ROOT = Path(\"../output/02_appendix1/audio_images\")  # Where to save the mels images\n",
    "TRAIN_AUDIO_IMAGES_SAVE_ROOT.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "\n",
    "def get_audio_info(filepath):\n",
    "    \"\"\"Get some properties from  an audio file\"\"\"\n",
    "    with SoundFile(filepath) as f:\n",
    "        sr = f.samplerate\n",
    "        frames = f.frames\n",
    "        duration = float(frames) / sr\n",
    "    return {\"frames\": frames, \"sr\": sr, \"duration\": duration}\n",
    "\n",
    "\n",
    "def make_df(n_splits=5, seed=SEED, nrows=None):\n",
    "    df = pd.read_csv(DATA_ROOT / \"train_metadata.csv\", nrows=nrows)\n",
    "\n",
    "    LABEL_IDS = {label: label_id for label_id, label in enumerate(sorted(df[\"primary_label\"].unique()))}\n",
    "\n",
    "    df = df.iloc[PART_INDEXES[PART_ID]: PART_INDEXES[PART_ID + 1]]\n",
    "\n",
    "    df[\"label_id\"] = df[\"primary_label\"].map(LABEL_IDS)\n",
    "\n",
    "    df[\"filepath\"] = [str(TRAIN_AUDIO_ROOT / primary_label / filename) for primary_label, filename in\n",
    "                      zip(df.primary_label, df.filename)]\n",
    "\n",
    "    pool = joblib.Parallel(4)\n",
    "    mapper = joblib.delayed(get_audio_info)\n",
    "    tasks = [mapper(filepath) for filepath in df.filepath]\n",
    "\n",
    "    df = pd.concat([df, pd.DataFrame(pool(tqdm(tasks)))], axis=1, sort=False)\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=n_splits, random_state=seed, shuffle=True)\n",
    "    splits = skf.split(np.arange(len(df)), y=df.label_id.values)\n",
    "    df[\"fold\"] = -1\n",
    "\n",
    "    for fold, (train_set, val_set) in enumerate(splits):\n",
    "        df.loc[df.index[val_set], \"fold\"] = fold\n",
    "\n",
    "    return LABEL_IDS, df\n",
    "\n",
    "\n",
    "LABEL_IDS, df = make_df(nrows=None)\n",
    "\n",
    "df.to_csv(\"rich_train_metadata.csv\", index=True)\n",
    "with open(\"LABEL_IDS.json\", \"w\") as f:\n",
    "    json.dump(LABEL_IDS, f)\n",
    "\n",
    "print(df.shape)\n",
    "df.head()\n",
    "\n",
    "\n",
    "class MelSpecComputer:\n",
    "    def __init__(self, sr, n_mels, fmin, fmax, **kwargs):\n",
    "        self.sr = sr\n",
    "        self.n_mels = n_mels\n",
    "        self.fmin = fmin\n",
    "        self.fmax = fmax\n",
    "        kwargs[\"n_fft\"] = kwargs.get(\"n_fft\", self.sr // 10)\n",
    "        kwargs[\"hop_length\"] = kwargs.get(\"hop_length\", self.sr // (10 * 4))\n",
    "        self.kwargs = kwargs\n",
    "\n",
    "    def __call__(self, y):\n",
    "        melspec = lb.feature.melspectrogram(\n",
    "            y, sr=self.sr, n_mels=self.n_mels, fmin=self.fmin, fmax=self.fmax, **self.kwargs,\n",
    "        )\n",
    "\n",
    "        melspec = lb.power_to_db(melspec).astype(np.float32)\n",
    "        return melspec\n",
    "\n",
    "\n",
    "def mono_to_color(X, eps=1e-6, mean=None, std=None):\n",
    "    mean = mean or X.mean()\n",
    "    std = std or X.std()\n",
    "    X = (X - mean) / (std + eps)\n",
    "\n",
    "    _min, _max = X.min(), X.max()\n",
    "\n",
    "    if (_max - _min) > eps:\n",
    "        V = np.clip(X, _min, _max)\n",
    "        V = 255 * (V - _min) / (_max - _min)\n",
    "        V = V.astype(np.uint8)\n",
    "    else:\n",
    "        V = np.zeros_like(X, dtype=np.uint8)\n",
    "\n",
    "    return V\n",
    "\n",
    "\n",
    "def crop_or_pad(y, length, is_train=True, start=None):\n",
    "    if len(y) < length:\n",
    "        y = np.concatenate([y, np.zeros(length - len(y))])\n",
    "\n",
    "        n_repeats = length // len(y)\n",
    "        epsilon = length % len(y)\n",
    "\n",
    "        y = np.concatenate([y] * n_repeats + [y[:epsilon]])\n",
    "\n",
    "    elif len(y) > length:\n",
    "        if not is_train:\n",
    "            start = start or 0\n",
    "        else:\n",
    "            start = start or np.random.randint(len(y) - length)\n",
    "\n",
    "        y = y[start:start + length]\n",
    "\n",
    "    return y\n",
    "\n",
    "\n",
    "class AudioToImage:\n",
    "    def __init__(self, sr=SR, n_mels=128, fmin=0, fmax=None, duration=DURATION, step=None, res_type=\"kaiser_fast\",\n",
    "                 resample=True):\n",
    "\n",
    "        self.sr = sr\n",
    "        self.n_mels = n_mels\n",
    "        self.fmin = fmin\n",
    "        self.fmax = fmax or self.sr // 2\n",
    "\n",
    "        self.duration = duration\n",
    "        self.audio_length = self.duration * self.sr\n",
    "        self.step = step or self.audio_length\n",
    "\n",
    "        self.res_type = res_type\n",
    "        self.resample = resample\n",
    "\n",
    "        self.mel_spec_computer = MelSpecComputer(sr=self.sr, n_mels=self.n_mels, fmin=self.fmin,\n",
    "                                                 fmax=self.fmax)\n",
    "\n",
    "    def audio_to_image(self, audio):\n",
    "        melspec = self.mel_spec_computer(audio)\n",
    "        image = mono_to_color(melspec)\n",
    "        #         image = normalize(image, mean=None, std=None)\n",
    "        return image\n",
    "\n",
    "    def __call__(self, row, save=True):\n",
    "        #       max_audio_duration = 10*self.duration\n",
    "        #       init_audio_length = max_audio_duration*row.sr\n",
    "\n",
    "        #       start = 0 if row.duration <  max_audio_duration else np.random.randint(row.frames - init_audio_length)\n",
    "\n",
    "        audio, orig_sr = sf.read(row.filepath, dtype=\"float32\")\n",
    "\n",
    "        if self.resample and orig_sr != self.sr:\n",
    "            audio = lb.resample(audio, orig_sr, self.sr, res_type=self.res_type)\n",
    "\n",
    "        audios = [audio[i:i + self.audio_length] for i in\n",
    "                  range(0, max(1, len(audio) - self.audio_length + 1), self.step)]\n",
    "        audios[-1] = crop_or_pad(audios[-1], length=self.audio_length)\n",
    "        images = [self.audio_to_image(audio) for audio in audios]\n",
    "        images = np.stack(images)\n",
    "\n",
    "        if save:\n",
    "            path = TRAIN_AUDIO_IMAGES_SAVE_ROOT / f\"{row.primary_label}/{row.filename}.npy\"\n",
    "            path.parent.mkdir(exist_ok=True, parents=True)\n",
    "            np.save(str(path), images)\n",
    "        else:\n",
    "            return row.filename, images\n",
    "\n",
    "\n",
    "def get_audios_as_images(df):\n",
    "    pool = joblib.Parallel(2)\n",
    "\n",
    "    converter = AudioToImage(step=int(DURATION * 0.666 * SR))\n",
    "    mapper = joblib.delayed(converter)\n",
    "    tasks = [mapper(row) for row in df.itertuples(False)]\n",
    "\n",
    "    pool(tqdm(tasks))\n",
    "\n",
    "\n",
    "get_audios_as_images(df)\n",
    "\n",
    "row = df.loc[df.duration.idxmax()]\n",
    "mels = np.load(str((TRAIN_AUDIO_IMAGES_SAVE_ROOT / row.primary_label / row.filename).as_posix() + \".npy\"))\n",
    "print(mels.shape)\n",
    "lbd.specshow(mels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a31f96e3-b985-4dd7-8021-074ca835a805",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "class CFG:\n",
    "    debug = False\n",
    "    print_freq = 100\n",
    "    num_workers = 4\n",
    "    model_name = 'resnext50_32x4d'\n",
    "    dim = (128, 281)\n",
    "    epochs = 10\n",
    "    batch_size = 1\n",
    "    seed = 42\n",
    "    target_size = 2\n",
    "    fold = 0  #choose from [0,1,2,3,4]\n",
    "    pretrained = False\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "import sys\n",
    "!{sys.executable} -m pip install --quiet timm\n",
    "\n",
    "import os\n",
    "import math\n",
    "import time\n",
    "import random\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "from contextlib import contextmanager\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from functools import partial\n",
    "\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam, SGD\n",
    "import torchvision.models as models\n",
    "from torch.nn.parameter import Parameter\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts, CosineAnnealingLR, ReduceLROnPlateau\n",
    "\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "from albumentations import ImageOnlyTransform\n",
    "\n",
    "import timm\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import glob\n",
    "\n",
    "OUTPUT_DIR = '../output/03_appendix2/'\n",
    "if not os.path.exists(OUTPUT_DIR):\n",
    "    os.makedirs(OUTPUT_DIR)\n",
    "\n",
    "\n",
    "def get_score(y_true, y_pred):\n",
    "    return accuracy_score(y_true, y_pred)\n",
    "\n",
    "\n",
    "def get_confusion_matrix(y_true, y_pred):\n",
    "    return confusion_matrix(y_true, y_pred)\n",
    "\n",
    "\n",
    "@contextmanager\n",
    "def timer(name):\n",
    "    t0 = time.time()\n",
    "    LOGGER.info(f'[{name}] start')\n",
    "    yield\n",
    "    LOGGER.info(f'[{name}] done in {time.time() - t0:.0f} s.')\n",
    "\n",
    "\n",
    "def init_logger(log_file=OUTPUT_DIR + 'train.log'):\n",
    "    from logging import getLogger, INFO, FileHandler, Formatter, StreamHandler\n",
    "    logger = getLogger(__name__)\n",
    "    logger.setLevel(INFO)\n",
    "    handler1 = StreamHandler()\n",
    "    handler1.setFormatter(Formatter(\"%(message)s\"))\n",
    "    handler2 = FileHandler(filename=log_file)\n",
    "    handler2.setFormatter(Formatter(\"%(message)s\"))\n",
    "    logger.addHandler(handler1)\n",
    "    logger.addHandler(handler2)\n",
    "    return logger\n",
    "\n",
    "\n",
    "LOGGER = init_logger()\n",
    "\n",
    "\n",
    "def seed_torch(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "\n",
    "seed_torch(seed=CFG.seed)\n",
    "\n",
    "short = pd.read_csv('../input/birdclef-2021/train_metadata.csv')\n",
    "\n",
    "\n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.df = df\n",
    "        self.filenames = df['filename'].values\n",
    "        #self.labels = df['hasbird'].values\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_name = self.filenames[idx]\n",
    "        filepath = glob.glob(f'../generated/kkiller-birdclef-mels-computer-d7-part*/audio_images/*/{file_name}.npy')[0]\n",
    "        image = np.load(filepath)\n",
    "        image = np.stack((image,) * 3, -1)\n",
    "        augmented_images = []\n",
    "        if self.transform:\n",
    "            for i in range(image.shape[0]):\n",
    "                oneimage = image[i]\n",
    "                augmented = self.transform(image=oneimage)\n",
    "                oneimage = augmented['image']\n",
    "                augmented_images.append(oneimage)\n",
    "        #label = torch.tensor(self.labels[idx]).long()\n",
    "        return np.stack(augmented_images, axis=0)  #, label\n",
    "\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "\n",
    "def get_transforms(*, data):\n",
    "    if data == 'train':\n",
    "        return A.Compose([\n",
    "            A.Resize(CFG.dim[0], CFG.dim[1]),\n",
    "            A.HorizontalFlip(p=0.5),\n",
    "            A.VerticalFlip(p=0.5),\n",
    "            A.augmentations.transforms.JpegCompression(p=0.5),\n",
    "            A.Normalize(\n",
    "                mean=[0.485, 0.456, 0.406],\n",
    "                std=[0.229, 0.224, 0.225],\n",
    "            ),\n",
    "            ToTensorV2(),\n",
    "        ])\n",
    "\n",
    "    elif data == 'valid':\n",
    "        return A.Compose([\n",
    "            A.Resize(CFG.dim[0], CFG.dim[1]),\n",
    "            A.Normalize(\n",
    "                mean=[0.485, 0.456, 0.406],\n",
    "                std=[0.229, 0.224, 0.225],\n",
    "            ),\n",
    "            ToTensorV2(),\n",
    "        ])\n",
    "\n",
    "\n",
    "import torch.nn as nn\n",
    "import timm\n",
    "\n",
    "\n",
    "class CustomResNext(nn.Module):\n",
    "    def __init__(self, model_name='resnext50_32x4d', pretrained=True):\n",
    "        super().__init__()\n",
    "        self.model = timm.create_model(model_name, pretrained=pretrained)\n",
    "        n_features = self.model.fc.in_features\n",
    "        self.model.fc = nn.Linear(n_features, CFG.target_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def inference(model, states, test_loader, device):\n",
    "    model.to(device)\n",
    "    tk0 = tqdm(enumerate(test_loader), total=len(test_loader))\n",
    "    probs = []\n",
    "    count = 0\n",
    "    for i, (images) in tk0:\n",
    "        images = images[0]\n",
    "        images = images.to(device)\n",
    "        avg_preds = []\n",
    "        for state in states:\n",
    "            model.load_state_dict(state['model'])\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                y_preds = model(images)\n",
    "            avg_preds.append(y_preds.softmax(1).to('cpu').numpy())\n",
    "        avg_preds = np.mean(avg_preds, axis=0)\n",
    "        probs.append(avg_preds)\n",
    "        count += 1\n",
    "        if count % 100 == 0:\n",
    "            print(count)\n",
    "    #probs = np.concatenate(probs)\n",
    "    return np.asarray(probs)\n",
    "\n",
    "\n",
    "if CFG.debug == True:\n",
    "    short = short.sample(n=10)\n",
    "\n",
    "# TODO put model from build_nocall_detector.ipynb (stage [1]) to be read here\n",
    "MODEL_DIR = '../output/01_stage1/clef-nocall-2class2-5fold/'\n",
    "model = CustomResNext(CFG.model_name, pretrained=CFG.pretrained)\n",
    "states = [torch.load(MODEL_DIR + f'{CFG.model_name}_fold{CFG.fold}_best.pth'), ]\n",
    "test_dataset = TestDataset(short, transform=get_transforms(data='valid'))\n",
    "test_loader = DataLoader(test_dataset, batch_size=CFG.batch_size, shuffle=False,\n",
    "                         num_workers=CFG.num_workers, pin_memory=True)\n",
    "predictions = inference(model, states, test_loader, CFG.device)\n",
    "\n",
    "predictions = [i[:, 1] for i in predictions]\n",
    "predictions = [' '.join(map(str, j.tolist())) for j in predictions]\n",
    "short['nocalldetection'] = predictions\n",
    "short.to_csv(f'../output/03_appendix2/nocalldetection_for_shortaudio_fold{CFG.fold}.csv', index=False)\n",
    "\n",
    "short.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e262a9-d724-4b8f-bace-dccb5165e466",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install -q scikit-learn == 1.0.1 pysndfx SoundFile audiomentations pretrainedmodels efficientnet_pytorch resnest\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import librosa as lb\n",
    "import librosa.display as lbd\n",
    "import soundfile as sf\n",
    "from soundfile import SoundFile\n",
    "import pandas as pd\n",
    "from IPython.display import Audio\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from resnest.torch import resnest50\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import timm\n",
    "import os, random, gc\n",
    "import re, time, json\n",
    "from ast import literal_eval\n",
    "\n",
    "from IPython.display import Audio\n",
    "from sklearn.metrics import label_ranking_average_precision_score\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "import joblib\n",
    "import glob\n",
    "\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "import pretrainedmodels\n",
    "import resnest.torch as resnest_torch\n",
    "\n",
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "\n",
    "\n",
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "\n",
    "seed_everything()\n",
    "\n",
    "NUM_CLASSES = 397\n",
    "SR = 32_000\n",
    "DURATION = 7\n",
    "\n",
    "MAX_READ_SAMPLES = 10  # Each record will have 10 melspecs at most, you can increase this on Colab with High Memory Enabled\n",
    "\n",
    "\n",
    "class Config:\n",
    "    def __init__(self, debug: bool):\n",
    "        self.debug = debug\n",
    "\n",
    "        self.epochs = 1 if self.debug else 100  # 50\n",
    "\n",
    "        self.max_distance = None  # choose from [10, 20, None]\n",
    "        if self.max_distance is not None:\n",
    "            self.sites = [\"SSW\"]  # choose multiples from [\"COL\", \"COR\", \"SNE\", \"SSW\"]\n",
    "        else:\n",
    "            self.sites = None\n",
    "        self.max_duration = None  # choose from [15, 30, 60, None]\n",
    "        self.min_rating = None  # choose from [3, 4, None], best: 3?\n",
    "        self.max_spieces = None  # choose from [100, 200, 300, None], best: 300?\n",
    "        self.confidence_ub = 0.995  # Probability of birdsong occurrence, default: 0.995, choose from [0.5, 0.7, 0.9, 0.995]\n",
    "        self.use_high_confidence_only = False  # Whether to use only frames that are likely to be ringing (False performed better).\n",
    "        self.use_mixup = True\n",
    "        self.mixup_alpha = 0.5  # 5.0\n",
    "        self.secondary_labels_weight = 0.6  #0.6 > 0.8 > 0.3 for better performance\n",
    "        self.grouped_by_author = False\n",
    "        self.folds = [0, ]\n",
    "\n",
    "        self.use_weight = False\n",
    "        self.use_valid2020 = False\n",
    "        self.use_ff1010 = False\n",
    "\n",
    "        self.suffix = f\"_sr{SR}_d{DURATION}\"\n",
    "        if self.max_spieces:\n",
    "            self.suffix += f\"_spices-{self.max_spieces}\"\n",
    "        if self.min_rating:\n",
    "            self.suffix += f\"_rating-{self.min_rating}\"\n",
    "        if self.use_high_confidence_only:\n",
    "            self.suffix += f\"_high-confidence-only\"\n",
    "        if self.use_mixup:\n",
    "            self.suffix += f\"_miixup-{self.mixup_alpha}\"\n",
    "        if self.secondary_labels_weight:\n",
    "            self.suffix += f\"_2ndlw-{self.secondary_labels_weight}\"\n",
    "        if self.use_weight:\n",
    "            self.suffix += f\"_weight\"\n",
    "        if self.use_valid2020:\n",
    "            self.suffix += f\"_valid2020\"\n",
    "        if self.use_ff1010:\n",
    "            self.suffix += f\"_ff1010\"\n",
    "        if self.grouped_by_author:\n",
    "            self.suffix += f\"_grouped-by-auther\"\n",
    "\n",
    "    def to_dict(self):\n",
    "        return {\n",
    "            \"debug\": self.debug,\n",
    "            \"epochs\": self.epochs,\n",
    "            \"max_distance\": self.max_distance,\n",
    "            \"sites\": self.sites,\n",
    "            \"max_duration\": self.max_duration,\n",
    "            \"min_rating\": self.min_rating,\n",
    "            \"max_spieces\": self.max_spieces,\n",
    "            \"confidence_ub\": self.confidence_ub,\n",
    "            \"use_high_confidence_only\": self.use_high_confidence_only,\n",
    "            \"use_mixup\": self.use_mixup,\n",
    "            \"mixup_alpha\": self.mixup_alpha,\n",
    "            \"secondary_labels_weight\": self.secondary_labels_weight,\n",
    "            \"suffix\": self.suffix,\n",
    "            \"grouped_by_author\": self.grouped_by_author\n",
    "        }\n",
    "\n",
    "\n",
    "config = Config(debug=True)\n",
    "from pprint import pprint\n",
    "\n",
    "pprint(config.to_dict())\n",
    "\n",
    "MODEL_NAMES = [\n",
    "    # \"resnext101_32x8d_wsl\",\n",
    "    # \"resnest50\",\n",
    "    \"resnest26d\",\n",
    "    # \"tf_efficientnet_b0\",\n",
    "]\n",
    "\n",
    "GENERATED = Path('../generated/')\n",
    "MEL_PATHS = sorted(GENERATED.glob(\"kkiller-birdclef-mels-computer-d7-part?/rich_train_metadata.csv\"))\n",
    "TRAIN_LABEL_PATHS = sorted(GENERATED.glob(\"kkiller-birdclef-mels-computer-d7-part?/LABEL_IDS.json\"))\n",
    "\n",
    "MODEL_ROOT = Path(\"../output/04_stage2\")\n",
    "\n",
    "TRAIN_BATCH_SIZE = 64\n",
    "TRAIN_NUM_WORKERS = 2\n",
    "\n",
    "VAL_BATCH_SIZE = 64\n",
    "VAL_NUM_WORKERS = 2\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(\"Device:\", DEVICE)\n",
    "\n",
    "\n",
    "def get_df(mel_paths=MEL_PATHS, train_label_paths=TRAIN_LABEL_PATHS):\n",
    "    df = None\n",
    "    LABEL_IDS = {}\n",
    "\n",
    "    for file_path in mel_paths:\n",
    "        temp = pd.read_csv(str(file_path), index_col=0)\n",
    "        temp[\"impath\"] = temp.apply(\n",
    "            lambda row: file_path.parent / \"audio_images/{}/{}.npy\".format(row.primary_label, row.filename), axis=1)\n",
    "        df = temp if df is None else df.append(temp)\n",
    "\n",
    "    df[\"secondary_labels\"] = df[\"secondary_labels\"].apply(literal_eval)\n",
    "\n",
    "    for file_path in train_label_paths:\n",
    "        with open(str(file_path)) as f:\n",
    "            LABEL_IDS.update(json.load(f))\n",
    "\n",
    "    return LABEL_IDS, df\n",
    "\n",
    "\n",
    "from typing import List\n",
    "\n",
    "\n",
    "def get_locations() -> List[dict]:\n",
    "    return [{\n",
    "        \"site\": \"COL\",\n",
    "        \"latitude\": 5.57,\n",
    "        \"longitude\": -75.85\n",
    "    }, {\n",
    "        \"site\": \"COR\",\n",
    "        \"latitude\": 10.12,\n",
    "        \"longitude\": -84.51\n",
    "    }, {\n",
    "        \"site\": \"SNE\",\n",
    "        \"latitude\": 38.49,\n",
    "        \"longitude\": -119.95\n",
    "    }, {\n",
    "        \"site\": \"SSW\",\n",
    "        \"latitude\": 42.47,\n",
    "        \"longitude\": -76.45\n",
    "    }]\n",
    "\n",
    "\n",
    "def is_in_site(row, sites, max_distance):\n",
    "    for location in get_locations():\n",
    "        if location[\"site\"] in sites:\n",
    "            x = (row[\"latitude\"] - location[\"latitude\"])\n",
    "            y = (row[\"longitude\"] - location[\"longitude\"])\n",
    "            r = (x ** 2 + y ** 2) ** 0.5\n",
    "            if r < max_distance:\n",
    "                return True\n",
    "    return False\n",
    "\n",
    "\n",
    "LABEL_IDS, df = get_df()\n",
    "\n",
    "if config.grouped_by_author:\n",
    "    kf = StratifiedGroupKFold(n_splits=5)\n",
    "    x = df[[\"latitude\", \"longitude\"]].values\n",
    "    y = df[\"label_id\"].values\n",
    "    groups = df[\"author\"].values\n",
    "    df[\"fold\"] = -1\n",
    "    for kfold_index, (train_index, valid_index) in enumerate(kf.split(x, y, groups)):\n",
    "        df.loc[valid_index, \"fold\"] = kfold_index\n",
    "\n",
    "if config.debug:\n",
    "    df = df.head(100)\n",
    "\n",
    "print(\"before:%d\" % len(df))\n",
    "# Within a certain distance of the target area\n",
    "if config.max_distance is not None:\n",
    "    df = df[df.apply(lambda row: is_in_site(row, config.sites, config.max_distance), axis=1)]\n",
    "# Number of Species\n",
    "if config.max_spieces is not None:\n",
    "    s = df[\"primary_label\"].value_counts().head(config.max_spieces)\n",
    "    df = df[df[\"primary_label\"].isin(s.index)]\n",
    "if config.min_rating is not None:\n",
    "    df = df[df[\"rating\"] >= config.min_rating]\n",
    "if config.max_duration is not None:\n",
    "    df = df[df[\"duration\"] < config.max_duration]\n",
    "df = df.reset_index(drop=True)\n",
    "print(\"after:%d\" % len(df))\n",
    "\n",
    "print(df.shape)\n",
    "df.head()\n",
    "\n",
    "\n",
    "def get_model(name, num_classes=NUM_CLASSES):\n",
    "    if \"resnest50\" in name:\n",
    "        if not os.path.exists(\"resnest50-528c19ca.pth\"):\n",
    "            !wget https: // github.com / rwightman / pytorch-image-models / releases / download / v0.1-resnest / resnest50-528c19ca.pth\n",
    "        pretrained_weights = torch.load('resnest50-528c19ca.pth')\n",
    "        model = getattr(resnest_torch, name)(pretrained=False)\n",
    "        model.load_state_dict(pretrained_weights)\n",
    "    elif \"resnest\" in name:\n",
    "        model = getattr(timm.models.resnest, name)(pretrained=True)\n",
    "    elif name.startswith(\"resnext\") or name.startswith(\"resnet\"):\n",
    "        model = torch.hub.load(\"pytorch/vision:v0.6.0\", name, pretrained=True)\n",
    "    elif \"wsl\" in name:\n",
    "        model = torch.hub.load(\"facebookresearch/WSL-Images\", name)\n",
    "    elif name.startswith(\"tf_efficientnet\"):\n",
    "        model = getattr(timm.models.efficientnet, name)(pretrained=True)\n",
    "    elif \"efficientnet-b\" in name:\n",
    "        model = EfficientNet.from_pretrained(name)\n",
    "    else:\n",
    "        model = pretrainedmodels.__dict__[name](pretrained='imagenet')\n",
    "\n",
    "    if hasattr(model, \"fc\"):\n",
    "        nb_ft = model.fc.in_features\n",
    "        model.fc = nn.Linear(nb_ft, num_classes)\n",
    "    elif hasattr(model, \"_fc\"):\n",
    "        nb_ft = model._fc.in_features\n",
    "        model._fc = nn.Linear(nb_ft, num_classes)\n",
    "    elif hasattr(model, \"classifier\"):\n",
    "        nb_ft = model.classifier.in_features\n",
    "        model.classifier = nn.Linear(nb_ft, num_classes)\n",
    "    elif hasattr(model, \"last_linear\"):\n",
    "        nb_ft = model.last_linear.in_features\n",
    "        model.last_linear = nn.Linear(nb_ft, num_classes)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "import glob\n",
    "\n",
    "nocall_paths = glob.glob(\"../generated/train-short-audio-nocall-fold0to4/train_short_audio_nocall_fold0to4/*.csv\")\n",
    "probs_list = []\n",
    "for nocall_path in nocall_paths:\n",
    "    nocall_df = pd.read_csv(nocall_path)\n",
    "    probs = nocall_df[\"nocalldetection\"].apply(\n",
    "        lambda _: list(\n",
    "            map(\n",
    "                float,\n",
    "                _.split()\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    probs_list.append(probs)\n",
    "probs = []\n",
    "for di in range(len(nocall_df)):\n",
    "    one_row = []\n",
    "    for ni in range(len(nocall_paths)):\n",
    "        one_row.append(probs_list[ni][di])\n",
    "    probs.append(np.mean(one_row, axis=0).tolist())\n",
    "\n",
    "audio_prob_store = dict(zip(nocall_df[\"filename\"].tolist(), probs))\n",
    "\n",
    "# TODO this is set to false; investigate where to get this data from?\n",
    "if config.use_valid2020:\n",
    "    clef_2020_df = pd.read_csv(\"../input/birdclef2020-validation-audio-and-ground-truth-d5/rich_metadata.csv\",\n",
    "                               index_col=0)\n",
    "    clef_2020_df[\"fold\"] = clef_2020_df[\"file_fold\"] % 5\n",
    "    clef_2020_df[\"impath\"] = \"../input/birdclef2020-validation-audio-and-ground-truth-d5/\" + clef_2020_df[\n",
    "        \"primary_label\"] + \"/\" + clef_2020_df[\"filename\"] + \".npy\"\n",
    "    clef_2020_df[\"label_id\"] = -1\n",
    "    clef_2020_df = clef_2020_df[clef_2020_df[\"primary_label\"] == \"nocall\"]\n",
    "    clef_2020_df[\"secondary_labels\"] = [[] for i in range(len(clef_2020_df))]\n",
    "\n",
    "    # Update prob with nocall detector\n",
    "    probs = [[0] for i in range(len(clef_2020_df))]\n",
    "    prob_dict = dict(zip(clef_2020_df[\"filename\"].tolist(), probs))\n",
    "    audio_prob_store.update(prob_dict)\n",
    "\n",
    "    df = pd.concat([clef_2020_df, df]).reset_index(drop=True)\n",
    "\n",
    "if config.use_ff1010:\n",
    "    ff1010_df = pd.read_csv(\"../input/ff1010bird-duration7-1/rich_metadata.csv\", index_col=0)\n",
    "    ff1010_df[\"impath\"] = \"../input/ff1010bird-duration7-1/\" + ff1010_df[\"primary_label\"] + \"/\" + ff1010_df[\n",
    "        \"filename\"] + \".npy\"\n",
    "    ff1010_df = ff1010_df[ff1010_df[\"primary_label\"] == \"nocall\"]\n",
    "    ff1010_df[\"label_id\"] = -1\n",
    "    ff1010_df[\"fold\"] = ff1010_df.index % 5\n",
    "    ff1010_df[\"secondary_labels\"] = [[] for i in range(len(ff1010_df))]\n",
    "\n",
    "    # Update prob with nocall detector\n",
    "    probs = [[0] for i in range(len(ff1010_df))]\n",
    "    prob_dict = dict(zip(ff1010_df[\"filename\"].tolist(), probs))\n",
    "    audio_prob_store.update(prob_dict)\n",
    "\n",
    "    df = pd.concat([ff1010_df, df]).reset_index(drop=True)\n",
    "\n",
    "\n",
    "def load_data(df):\n",
    "    def load_row(row):\n",
    "        # impath = TRAIN_IMAGES_ROOT/f\"{row.primary_label}/{row.filename}.npy\"\n",
    "        return row.filename, np.load(str(row.impath))[:MAX_READ_SAMPLES]\n",
    "\n",
    "    pool = joblib.Parallel(4)\n",
    "    mapper = joblib.delayed(load_row)\n",
    "    tasks = [mapper(row) for row in df.itertuples(False)]\n",
    "    res = pool(tqdm(tasks))\n",
    "    res = dict(res)\n",
    "    return res\n",
    "\n",
    "\n",
    "# We cache the train set to reduce training time\n",
    "\n",
    "audio_image_store = load_data(df)\n",
    "len(audio_image_store)\n",
    "\n",
    "# print(\"shape:\", next(iter(audio_image_store.values())).shape)\n",
    "# lbd.specshow(next(iter(audio_image_store.values()))[0])\n",
    "\n",
    "for k, v in LABEL_IDS.items():\n",
    "    print(k, v)\n",
    "    break\n",
    "\n",
    "image_w = 281\n",
    "\n",
    "\n",
    "def pad_image(image, image_w=image_w):\n",
    "    h = image.shape[0]\n",
    "    w = image.shape[1]\n",
    "    if w < image_w:\n",
    "        start = np.random.choice((image_w - w))\n",
    "        ret = np.zeros((h, image_w))\n",
    "        ret[:, start:start + w] = image\n",
    "        return ret\n",
    "    return image\n",
    "\n",
    "\n",
    "class BirdClefDataset(Dataset):\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            audio_image_store,\n",
    "            audio_prob_store,\n",
    "            meta,\n",
    "            sr=SR,\n",
    "            is_train=True,\n",
    "            num_classes=NUM_CLASSES,\n",
    "            duration=DURATION,\n",
    "    ):\n",
    "        self.audio_image_store = audio_image_store\n",
    "        self.audio_prob_store = audio_prob_store\n",
    "        self.meta = meta.copy().reset_index(drop=True)\n",
    "        self.sr = sr\n",
    "        self.is_train = is_train\n",
    "        self.num_classes = num_classes\n",
    "        self.duration = duration\n",
    "        self.audio_length = self.duration * self.sr\n",
    "        self.eps = 0.0025\n",
    "\n",
    "    @staticmethod\n",
    "    def normalize(image):\n",
    "        image = image.astype(\"float32\", copy=False) / 255.0\n",
    "        image = np.stack([image, image, image])\n",
    "        return image\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.meta)\n",
    "\n",
    "    def mixup_data(self, image, noize, alpha=0.5):\n",
    "        if alpha > 0.:\n",
    "            lam = np.random.beta(alpha, alpha)\n",
    "        else:\n",
    "            lam = 1.\n",
    "        lam /= 2  # leave it at half maximum.\n",
    "        mixed_x = (1 - lam) * image + lam * noize\n",
    "        return mixed_x\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.meta.iloc[idx]\n",
    "        images = self.audio_image_store[row.filename]\n",
    "        probs = self.audio_prob_store[row.filename]\n",
    "\n",
    "        i = np.random.choice(len(images))\n",
    "        image = images[i]\n",
    "\n",
    "        if image.shape[1] < self.audio_length:\n",
    "            image = pad_image(image, image_w)\n",
    "\n",
    "        image = self.normalize(image)\n",
    "        prob = probs[i]\n",
    "        t = np.zeros(self.num_classes, dtype=np.float32) + self.eps  # Label smoothing\n",
    "        t[row.label_id] = max(min(prob, config.confidence_ub), self.eps)  # clipping\n",
    "        for secondary_label in row.secondary_labels:\n",
    "            # Set a lower value than the primary label\n",
    "            if secondary_label in LABEL_IDS:\n",
    "                t[LABEL_IDS[secondary_label]] = max(self.eps, prob * 0.6)\n",
    "\n",
    "        return image, t\n",
    "\n",
    "\n",
    "ds = BirdClefDataset(audio_image_store, audio_prob_store, meta=df, sr=SR, duration=DURATION, is_train=True)\n",
    "\n",
    "\n",
    "# TODO set use_cuda=True on cluster\n",
    "def mixup_data(x, y, alpha=0.5, use_cuda=False):\n",
    "    if alpha > 0.:\n",
    "        lam = np.random.beta(alpha, alpha)\n",
    "    else:\n",
    "        lam = 1.\n",
    "    batch_size = x.size()[0]\n",
    "    if use_cuda:\n",
    "        index = torch.randperm(batch_size).cuda()\n",
    "    else:\n",
    "        index = torch.randperm(batch_size)\n",
    "\n",
    "    mixed_x = lam * x + (1 - lam) * x[index, :]\n",
    "    mixed_y = lam * y + (1 - lam) * y[index]\n",
    "    #mixed_y = torch.maximum(y, y[index])\n",
    "    return mixed_x, mixed_y, lam\n",
    "\n",
    "\n",
    "def one_step(xb, yb, net, criterion, optimizer, scheduler=None):\n",
    "    if config.use_mixup:\n",
    "        xb, yb, lam = mixup_data(xb, yb, alpha=config.mixup_alpha)\n",
    "    xb, yb = xb.to(DEVICE), yb.to(DEVICE)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    o = net(xb)\n",
    "    loss = criterion(o, yb)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        l = loss.item()\n",
    "\n",
    "        o = o.sigmoid()\n",
    "        yb = (yb > 0.5) * 1.0\n",
    "        lrap = label_ranking_average_precision_score(yb.cpu().numpy(), o.cpu().numpy())\n",
    "\n",
    "        o = (o > 0.5) * 1.0\n",
    "\n",
    "        prec = (o * yb).sum() / (1e-6 + o.sum())\n",
    "        rec = (o * yb).sum() / (1e-6 + yb.sum())\n",
    "        f1 = 2 * prec * rec / (1e-6 + prec + rec)\n",
    "\n",
    "    if scheduler is not None:\n",
    "        scheduler.step()\n",
    "\n",
    "    return l, lrap, f1.item(), rec.item(), prec.item()\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(net, criterion, val_laoder):\n",
    "    net.eval()\n",
    "\n",
    "    os, y = [], []\n",
    "    val_laoder = tqdm(val_laoder, leave=False, total=len(val_laoder))\n",
    "\n",
    "    for icount, (xb, yb) in enumerate(val_laoder):\n",
    "        y.append(yb.to(DEVICE))\n",
    "\n",
    "        xb = xb.to(DEVICE)\n",
    "        o = net(xb)\n",
    "\n",
    "        os.append(o)\n",
    "\n",
    "    y = torch.cat(y)\n",
    "    o = torch.cat(os)\n",
    "\n",
    "    l = criterion(o, y).item()\n",
    "\n",
    "    o = o.sigmoid()\n",
    "    y = (y > 0.5) * 1.0\n",
    "\n",
    "    lrap = label_ranking_average_precision_score(y.cpu().numpy(), o.cpu().numpy())\n",
    "\n",
    "    o = (o > 0.5) * 1.0\n",
    "\n",
    "    prec = ((o * y).sum() / (1e-6 + o.sum())).item()\n",
    "    rec = ((o * y).sum() / (1e-6 + y.sum())).item()\n",
    "    f1 = 2 * prec * rec / (1e-6 + prec + rec)\n",
    "\n",
    "    return l, lrap, f1, rec, prec\n",
    "\n",
    "\n",
    "def one_epoch(net, criterion, optimizer, scheduler, train_laoder, val_laoder):\n",
    "    net.train()\n",
    "    l, lrap, prec, rec, f1, icount = 0., 0., 0., 0., 0., 0\n",
    "    train_laoder = tqdm(train_laoder, leave=False)\n",
    "    epoch_bar = train_laoder\n",
    "\n",
    "    for (xb, yb) in epoch_bar:\n",
    "        # epoch_bar.set_description(\"----|----|----|----|---->\")\n",
    "        _l, _lrap, _f1, _rec, _prec = one_step(xb, yb, net, criterion, optimizer)\n",
    "        l += _l\n",
    "        lrap += _lrap\n",
    "        f1 += _f1\n",
    "        rec += _rec\n",
    "        prec += _prec\n",
    "\n",
    "        icount += 1\n",
    "\n",
    "        if hasattr(epoch_bar, \"set_postfix\") and not icount % 10:\n",
    "            epoch_bar.set_postfix(\n",
    "                loss=\"{:.6f}\".format(l / icount),\n",
    "                lrap=\"{:.3f}\".format(lrap / icount),\n",
    "                prec=\"{:.3f}\".format(prec / icount),\n",
    "                rec=\"{:.3f}\".format(rec / icount),\n",
    "                f1=\"{:.3f}\".format(f1 / icount),\n",
    "            )\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "    l /= icount\n",
    "    lrap /= icount\n",
    "    f1 /= icount\n",
    "    rec /= icount\n",
    "    prec /= icount\n",
    "\n",
    "    l_val, lrap_val, f1_val, rec_val, prec_val = evaluate(net, criterion, val_laoder)\n",
    "\n",
    "    return (l, l_val), (lrap, lrap_val), (f1, f1_val), (rec, rec_val), (prec, prec_val)\n",
    "\n",
    "\n",
    "class AutoSave:\n",
    "    def __init__(self, top_k=50, metric=\"f1\", mode=\"min\", root=None, name=\"ckpt\"):\n",
    "        self.top_k = top_k\n",
    "        self.logs = []\n",
    "        self.metric = metric\n",
    "        self.mode = mode\n",
    "        self.root = Path(root or MODEL_ROOT)\n",
    "        assert self.root.exists()\n",
    "        self.name = name\n",
    "\n",
    "        self.top_models = []\n",
    "        self.top_metrics = []\n",
    "\n",
    "    def log(self, model, metrics):\n",
    "        metric = metrics[self.metric]\n",
    "        rank = self.rank(metric)\n",
    "\n",
    "        self.top_metrics.insert(rank + 1, metric)\n",
    "        if len(self.top_metrics) > self.top_k:\n",
    "            self.top_metrics.pop(0)\n",
    "\n",
    "        self.logs.append(metrics)\n",
    "        self.save(model, metric, rank, metrics[\"epoch\"])\n",
    "\n",
    "    def save(self, model, metric, rank, epoch):\n",
    "        t = time.strftime(\"%Y%m%d%H%M%S\")\n",
    "        name = \"{}_epoch_{:02d}_{}_{:.04f}_{}\".format(self.name, epoch, self.metric, metric, t)\n",
    "        name = re.sub(r\"[^\\w_-]\", \"\", name) + \".pth\"\n",
    "        path = self.root.joinpath(name)\n",
    "\n",
    "        old_model = None\n",
    "        self.top_models.insert(rank + 1, name)\n",
    "        if len(self.top_models) > self.top_k:\n",
    "            old_model = self.root.joinpath(self.top_models[0])\n",
    "            self.top_models.pop(0)\n",
    "\n",
    "        torch.save(model.state_dict(), path.as_posix())\n",
    "\n",
    "        if old_model is not None:\n",
    "            old_model.unlink()\n",
    "\n",
    "        self.to_json()\n",
    "\n",
    "    def rank(self, val):\n",
    "        r = -1\n",
    "        for top_val in self.top_metrics:\n",
    "            if val <= top_val:\n",
    "                return r\n",
    "            r += 1\n",
    "\n",
    "        return r\n",
    "\n",
    "    def to_json(self):\n",
    "        # t = time.strftime(\"%Y%m%d%H%M%S\")\n",
    "        name = \"{}_logs\".format(self.name)\n",
    "        name = re.sub(r\"[^\\w_-]\", \"\", name) + \".json\"\n",
    "        path = self.root.joinpath(name)\n",
    "\n",
    "        with path.open(\"w\") as f:\n",
    "            json.dump(self.logs, f, indent=2)\n",
    "\n",
    "\n",
    "def one_fold(model_name, fold, train_set, val_set, epochs=20, save=True, save_root=None):\n",
    "    save_root = Path(save_root) or MODEL_ROOT\n",
    "\n",
    "    saver = AutoSave(root=save_root, name=f\"birdclef_{model_name}_fold{fold}\", metric=\"f1_val\")\n",
    "\n",
    "    net = get_model(model_name).to(DEVICE)\n",
    "\n",
    "    #criterion = nn.BCEWithLogitsLoss()\n",
    "    weight = None\n",
    "    if config.use_weight:\n",
    "        label_inv = (1 / df[\"label_id\"].value_counts().sort_index()).values\n",
    "        label_inv_mean = label_inv.mean()\n",
    "        weight = label_inv * (1 / label_inv_mean)  # Inverse proportion such that the mean is 1\n",
    "        weight = torch.tensor(weight).to(DEVICE)\n",
    "    criterion = nn.BCEWithLogitsLoss(weight=weight)\n",
    "\n",
    "    lr = 8e-4\n",
    "    optimizer = optim.Adam(net.parameters(), lr=lr)\n",
    "    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, eta_min=1e-5, T_max=epochs)\n",
    "\n",
    "    train_data = BirdClefDataset(\n",
    "        audio_image_store,\n",
    "        audio_prob_store,\n",
    "        meta=df.iloc[train_set].reset_index(drop=True),\n",
    "        sr=SR,\n",
    "        duration=DURATION,\n",
    "        is_train=True\n",
    "    )\n",
    "    train_laoder = DataLoader(train_data, batch_size=TRAIN_BATCH_SIZE, num_workers=TRAIN_NUM_WORKERS, shuffle=True,\n",
    "                              pin_memory=True)\n",
    "\n",
    "    val_data = BirdClefDataset(\n",
    "        audio_image_store,\n",
    "        audio_prob_store,\n",
    "        meta=df.iloc[val_set].reset_index(drop=True),\n",
    "        sr=SR,\n",
    "        duration=DURATION,\n",
    "        is_train=False)\n",
    "    val_laoder = DataLoader(val_data, batch_size=VAL_BATCH_SIZE, num_workers=VAL_NUM_WORKERS, shuffle=False)\n",
    "\n",
    "    epochs_bar = tqdm(list(range(epochs)), leave=False)\n",
    "    for epoch in epochs_bar:\n",
    "        epochs_bar.set_description(f\"--> [EPOCH {epoch:02d}]\")\n",
    "        net.train()\n",
    "\n",
    "        (l, l_val), (lrap, lrap_val), (f1, f1_val), (rec, rec_val), (prec, prec_val) = one_epoch(\n",
    "            net=net,\n",
    "            criterion=criterion,\n",
    "            optimizer=optimizer,\n",
    "            scheduler=scheduler,\n",
    "            train_laoder=train_laoder,\n",
    "            val_laoder=val_laoder,\n",
    "        )\n",
    "\n",
    "        epochs_bar.set_postfix(\n",
    "            loss=\"({:.6f}, {:.6f})\".format(l, l_val),\n",
    "            prec=\"({:.3f}, {:.3f})\".format(prec, prec_val),\n",
    "            rec=\"({:.3f}, {:.3f})\".format(rec, rec_val),\n",
    "            f1=\"({:.3f}, {:.3f})\".format(f1, f1_val),\n",
    "            lrap=\"({:.3f}, {:.3f})\".format(lrap, lrap_val),\n",
    "        )\n",
    "\n",
    "        print(\n",
    "            \"[{epoch:02d}] loss: {loss} lrap: {lrap} f1: {f1} rec: {rec} prec: {prec}\".format(\n",
    "                epoch=epoch,\n",
    "                loss=\"({:.6f}, {:.6f})\".format(l, l_val),\n",
    "                prec=\"({:.3f}, {:.3f})\".format(prec, prec_val),\n",
    "                rec=\"({:.3f}, {:.3f})\".format(rec, rec_val),\n",
    "                f1=\"({:.3f}, {:.3f})\".format(f1, f1_val),\n",
    "                lrap=\"({:.3f}, {:.3f})\".format(lrap, lrap_val),\n",
    "            )\n",
    "        )\n",
    "\n",
    "        if save:\n",
    "            metrics = {\n",
    "                \"loss\": l, \"lrap\": lrap, \"f1\": f1, \"rec\": rec, \"prec\": prec,\n",
    "                \"loss_val\": l_val, \"lrap_val\": lrap_val, \"f1_val\": f1_val, \"rec_val\": rec_val, \"prec_val\": prec_val,\n",
    "                \"epoch\": epoch,\n",
    "            }\n",
    "\n",
    "            saver.log(net, metrics)\n",
    "\n",
    "\n",
    "def train(model_name, epochs=20, save=True, n_splits=5, seed=177, save_root=None, suffix=\"\", folds=None):\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    save_root = save_root or MODEL_ROOT / f\"{model_name}{suffix}\"\n",
    "    save_root.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "    fold_bar = tqdm(df.reset_index().groupby(\"fold\").index.apply(list).items(), total=df.fold.max() + 1)\n",
    "\n",
    "    for fold, val_set in fold_bar:\n",
    "        if folds and not fold in folds:\n",
    "            continue\n",
    "\n",
    "        print(f\"\\n############################### [FOLD {fold}]\")\n",
    "        fold_bar.set_description(f\"[FOLD {fold}]\")\n",
    "        train_set = np.setdiff1d(df.index, val_set)\n",
    "\n",
    "        one_fold(model_name, fold=fold, train_set=train_set, val_set=val_set, epochs=epochs, save=save,\n",
    "                 save_root=save_root)\n",
    "\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "\n",
    "for model_name in MODEL_NAMES:\n",
    "    print(\"\\n\\n###########################################\", model_name.upper())\n",
    "    train(model_name, epochs=config.epochs, suffix=config.suffix, folds=config.folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5999c739-91be-469b-ab69-1952b724c6d9",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install -q pysndfx SoundFile audiomentations pretrainedmodels efficientnet_pytorch resnest\n",
    "!{sys.executable} -m pip install timm\n",
    "\n",
    "import numpy as np\n",
    "import librosa as lb\n",
    "import librosa.display as lbd\n",
    "import soundfile as sf\n",
    "from soundfile import SoundFile\n",
    "import pandas as pd\n",
    "from IPython.display import Audio\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from resnest.torch import resnest50\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import os, random, gc\n",
    "import re, time, json\n",
    "from ast import literal_eval\n",
    "\n",
    "from IPython.display import Audio\n",
    "from sklearn.metrics import label_ranking_average_precision_score\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "import joblib\n",
    "\n",
    "import timm\n",
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "import pretrainedmodels\n",
    "import resnest.torch as resnest_torch\n",
    "\n",
    "if not os.path.exists(\"../generated/resnest50-528c19ca.pth\"):\n",
    "    !wget  \"https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-resnest/resnest50-528c19ca.pth\"\n",
    "\n",
    "\n",
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "\n",
    "seed_everything()\n",
    "\n",
    "NUM_CLASSES = 397\n",
    "SR = 32_000\n",
    "DURATION = 7\n",
    "\n",
    "MAX_READ_SAMPLES = 15  # Each record will have 10 melspecs at most, you can increase this on Colab with High Memory Enabled\n",
    "\n",
    "\n",
    "class Config:\n",
    "    def __init__(self, debug: bool):\n",
    "        self.debug = debug\n",
    "\n",
    "        self.epochs = 1 if self.debug else 50\n",
    "\n",
    "        self.max_distance = None  # choose from [10, 20, None]\n",
    "        if self.max_distance is not None:\n",
    "            self.sites = [\"SSW\"]  # choose multiples from [\"COL\", \"COR\", \"SNE\", \"SSW\"]\n",
    "        else:\n",
    "            self.sites = None\n",
    "        self.max_duration = None  # choose from [15, 30, 60, None]\n",
    "        self.min_rating = None  # choose from [3, 4, None], best: 3?\n",
    "        self.max_spieces = None  # choose from [100, 200, 300, None], best: 300?\n",
    "        self.confidence_ub = 0.995  # Probability of birdsong occurrence, default: 0.995, choose from [0.5, 0.7, 0.9, 0.995]\n",
    "        self.use_high_confidence_only = False  # Whether to use only frames that are likely to be ringing (False performed better).\n",
    "        self.use_mixup = True\n",
    "        self.mixup_alpha = 5.0  # 0.5\n",
    "        self.grouped_by_author = True\n",
    "        # self.folds = [4]\n",
    "\n",
    "        self.suffix = f\"sr{SR}_d{DURATION}\"\n",
    "        if self.max_spieces:\n",
    "            self.suffix += f\"_spices-{self.max_spieces}\"\n",
    "        if self.min_rating:\n",
    "            self.suffix += f\"_rating-{self.min_rating}\"\n",
    "        if self.use_high_confidence_only:\n",
    "            self.suffix += f\"_high-confidence-only\"\n",
    "        if self.use_mixup:\n",
    "            self.suffix += f\"_miixup-{self.mixup_alpha}\"\n",
    "        if self.grouped_by_author:\n",
    "            self.suffix += f\"_grouped-by-auther\"\n",
    "\n",
    "    def to_dict(self):\n",
    "        return {\n",
    "            \"debug\": self.debug,\n",
    "            \"epochs\": self.epochs,\n",
    "            \"max_distance\": self.max_distance,\n",
    "            \"sites\": self.sites,\n",
    "            \"max_duration\": self.max_duration,\n",
    "            \"min_rating\": self.min_rating,\n",
    "            \"max_spieces\": self.max_spieces,\n",
    "            \"confidence_ub\": self.confidence_ub,\n",
    "            \"use_high_confidence_only\": self.use_high_confidence_only,\n",
    "            \"use_mixup\": self.use_mixup,\n",
    "            \"mixup_alpha\": self.mixup_alpha,\n",
    "            \"suffix\": self.suffix,\n",
    "            \"grouped_by_author\": self.grouped_by_author\n",
    "        }\n",
    "\n",
    "\n",
    "config = Config(debug=False)\n",
    "from pprint import pprint\n",
    "\n",
    "pprint(config.to_dict())\n",
    "\n",
    "MODEL_NAMES = [\n",
    "    # \"resnext101_32x8d_wsl\",\n",
    "    # 'efficientnet_b0',\n",
    "    \"resnest50\",\n",
    "    # \"densenet121\",\n",
    "]\n",
    "\n",
    "MEL_PATHS = sorted(Path(\"../generated\").glob(\"kkiller-birdclef-mels-computer-d7-part?/rich_train_metadata.csv\"))\n",
    "TRAIN_LABEL_PATHS = sorted(Path(\"../generated\").glob(\"kkiller-birdclef-mels-computer-d7-part?/LABEL_IDS.json\"))\n",
    "\n",
    "TRAIN_BATCH_SIZE = 50  # 16\n",
    "TRAIN_NUM_WORKERS = 2\n",
    "\n",
    "VAL_BATCH_SIZE = 50  # 16 # 128\n",
    "VAL_NUM_WORKERS = 2\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(\"Device:\", DEVICE)\n",
    "\n",
    "checkpoint_paths = [\n",
    "    # model1\n",
    "    Path(\"../generated/clefmodel/birdclef_resnest50_fold0_epoch_27_f1_val_05179_20210520120053.pth\"),\n",
    "]\n",
    "\n",
    "\n",
    "def get_df(mel_paths=MEL_PATHS, train_label_paths=TRAIN_LABEL_PATHS):\n",
    "    df = None\n",
    "    LABEL_IDS = {}\n",
    "\n",
    "    for file_path in mel_paths:\n",
    "        temp = pd.read_csv(str(file_path), index_col=0)\n",
    "        temp[\"impath\"] = temp.apply(\n",
    "            lambda row: file_path.parent / \"audio_images/{}/{}.npy\".format(row.primary_label, row.filename), axis=1)\n",
    "        df = temp if df is None else df.append(temp)\n",
    "\n",
    "    df[\"secondary_labels\"] = df[\"secondary_labels\"].apply(literal_eval)\n",
    "\n",
    "    for file_path in train_label_paths:\n",
    "        with open(str(file_path)) as f:\n",
    "            LABEL_IDS.update(json.load(f))\n",
    "\n",
    "    return LABEL_IDS, df\n",
    "\n",
    "\n",
    "from typing import List\n",
    "\n",
    "\n",
    "def get_locations() -> List[dict]:\n",
    "    return [{\n",
    "        \"site\": \"COL\",\n",
    "        \"latitude\": 5.57,\n",
    "        \"longitude\": -75.85\n",
    "    }, {\n",
    "        \"site\": \"COR\",\n",
    "        \"latitude\": 10.12,\n",
    "        \"longitude\": -84.51\n",
    "    }, {\n",
    "        \"site\": \"SNE\",\n",
    "        \"latitude\": 38.49,\n",
    "        \"longitude\": -119.95\n",
    "    }, {\n",
    "        \"site\": \"SSW\",\n",
    "        \"latitude\": 42.47,\n",
    "        \"longitude\": -76.45\n",
    "    }]\n",
    "\n",
    "\n",
    "def is_in_site(row, sites, max_distance):\n",
    "    for location in get_locations():\n",
    "        if location[\"site\"] in sites:\n",
    "            x = (row[\"latitude\"] - location[\"latitude\"])\n",
    "            y = (row[\"longitude\"] - location[\"longitude\"])\n",
    "            r = (x ** 2 + y ** 2) ** 0.5\n",
    "            if r < max_distance:\n",
    "                return True\n",
    "    return False\n",
    "\n",
    "\n",
    "LABEL_IDS, df = get_df()\n",
    "\n",
    "if config.grouped_by_author:\n",
    "    kf = StratifiedGroupKFold(n_splits=5)\n",
    "    x = df[[\"latitude\", \"longitude\"]].values\n",
    "    y = df[\"label_id\"].values\n",
    "    groups = df[\"author\"].values\n",
    "    df[\"fold\"] = -1\n",
    "    for kfold_index, (train_index, valid_index) in enumerate(kf.split(x, y, groups)):\n",
    "        df.loc[valid_index, \"fold\"] = kfold_index\n",
    "\n",
    "if config.debug:\n",
    "    df = df.head(100)\n",
    "\n",
    "print(\"before:%d\" % len(df))\n",
    "# Within a certain distance of the target area\n",
    "if config.max_distance is not None:\n",
    "    df = df[df.apply(lambda row: is_in_site(row, config.sites, config.max_distance), axis=1)]\n",
    "# Number of Species\n",
    "if config.max_spieces is not None:\n",
    "    s = df[\"primary_label\"].value_counts().head(config.max_spieces)\n",
    "    df = df[df[\"primary_label\"].isin(s.index)]\n",
    "# Rating is above a certain value\n",
    "if config.min_rating is not None:\n",
    "    df = df[df[\"rating\"] >= config.min_rating]\n",
    "# Within a certain amount of recording time\n",
    "if config.max_duration is not None:\n",
    "    df = df[df[\"duration\"] < config.max_duration]\n",
    "df = df.reset_index(drop=True)\n",
    "print(\"after:%d\" % len(df))\n",
    "\n",
    "print(df.shape)\n",
    "df.head()\n",
    "\n",
    "\n",
    "def get_model(name, num_classes=NUM_CLASSES):\n",
    "    if \"resnest\" in name:\n",
    "        if not os.path.exists(\"../generated/resnest50-528c19ca.pth\"):\n",
    "            !wget https: // github.com / rwightman / pytorch-image-models / releases / download / v0.1-resnest / resnest50-528c19ca.pth\n",
    "\n",
    "        pretrained_weights = torch.load('../generated/resnest50-528c19ca.pth')\n",
    "        model = getattr(resnest_torch, name)(pretrained=False)\n",
    "        model.load_state_dict(pretrained_weights)\n",
    "    elif \"wsl\" in name:\n",
    "        model = torch.hub.load(\"facebookresearch/WSL-Images\", name)\n",
    "    elif name.startswith(\"resnext\") or name.startswith(\"resnet\"):\n",
    "        model = torch.hub.load(\"pytorch/vision:v0.6.0\", name, pretrained=True)\n",
    "    elif name.startswith(\"efficientnet_b\"):\n",
    "        model = getattr(timm.models.efficientnet, name)(pretrained=True)\n",
    "    elif name.startswith(\"densenet\"):\n",
    "        model = getattr(timm.models.densenet, name)(pretrained=True)\n",
    "    elif \"efficientnet-b\" in name:\n",
    "        model = EfficientNet.from_pretrained(name)\n",
    "    else:\n",
    "        model = pretrainedmodels.__dict__[name](pretrained='imagenet')\n",
    "\n",
    "    if hasattr(model, \"fc\"):\n",
    "        nb_ft = model.fc.in_features\n",
    "        model.fc = nn.Linear(nb_ft, num_classes)\n",
    "    elif hasattr(model, \"_fc\"):\n",
    "        nb_ft = model._fc.in_features\n",
    "        model._fc = nn.Linear(nb_ft, num_classes)\n",
    "    elif hasattr(model, \"classifier\"):\n",
    "        nb_ft = model.classifier.in_features\n",
    "        model.classifier = nn.Linear(nb_ft, num_classes)\n",
    "    elif hasattr(model, \"last_linear\"):\n",
    "        nb_ft = model.last_linear.in_features\n",
    "        model.last_linear = nn.Linear(nb_ft, num_classes)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "class BirdClefDataset(Dataset):\n",
    "    def __init__(\n",
    "            self,\n",
    "            meta,\n",
    "            sr=SR,\n",
    "            is_train=True,\n",
    "            num_classes=NUM_CLASSES,\n",
    "            duration=DURATION\n",
    "    ):\n",
    "        self.meta = meta.copy().reset_index(drop=True)\n",
    "        records = []\n",
    "        for idx, row in tqdm(self.meta.iterrows(), total=len(self.meta)):\n",
    "            images = np.load(str(row[\"impath\"]))\n",
    "            for i, image in enumerate(images):\n",
    "                seconds = i * duration\n",
    "                records.append({\n",
    "                    \"filename\": row[\"filename\"],\n",
    "                    \"impath\": row[\"impath\"],\n",
    "                    \"seconds\": seconds,\n",
    "                    \"index\": i\n",
    "                })\n",
    "        self.records = records\n",
    "        self.sr = sr\n",
    "        self.is_train = is_train\n",
    "        self.num_classes = num_classes\n",
    "        self.duration = duration\n",
    "        self.audio_length = self.duration * self.sr\n",
    "        self.eps = 0.0025\n",
    "\n",
    "    @staticmethod\n",
    "    def normalize(image):\n",
    "        image = image.astype(\"float32\", copy=False) / 255.0\n",
    "        image = np.stack([image, image, image])\n",
    "        return image\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.records)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.records[idx]\n",
    "        image = np.load(str(row[\"impath\"]))[row[\"index\"]]\n",
    "        image = self.normalize(image)\n",
    "        return image, row[\"filename\"], row[\"seconds\"]\n",
    "\n",
    "\n",
    "nocall_df = pd.read_csv(\n",
    "    \"../generated/train-short-audio-nocall-fold0to4/train_short_audio_nocall_fold0to4/nocalldetection_for_shortaudio_fold0.csv\")\n",
    "\n",
    "ds = BirdClefDataset(meta=df, sr=SR, duration=DURATION, is_train=True)\n",
    "len(df)\n",
    "\n",
    "\n",
    "def add_tail(model, num_classes):\n",
    "    if hasattr(model, \"fc\"):\n",
    "        nb_ft = model.fc.in_features\n",
    "        model.fc = nn.Linear(nb_ft, num_classes)\n",
    "    elif hasattr(model, \"_fc\"):\n",
    "        nb_ft = model._fc.in_features\n",
    "        model._fc = nn.Linear(nb_ft, num_classes)\n",
    "    elif hasattr(model, \"classifier\"):\n",
    "        nb_ft = model.classifier.in_features\n",
    "        model.classifier = nn.Linear(nb_ft, num_classes)\n",
    "    elif hasattr(model, \"last_linear\"):\n",
    "        nb_ft = model.last_linear.in_features\n",
    "        model.last_linear = nn.Linear(nb_ft, num_classes)\n",
    "    return model\n",
    "\n",
    "\n",
    "def load_net(checkpoint_path, num_classes=NUM_CLASSES):\n",
    "    if \"resnest50\" in checkpoint_path:\n",
    "        net = resnest50(pretrained=False)\n",
    "    elif \"resnest26d\" in checkpoint_path:\n",
    "        net = timm.models.resnest26d(pretrained=False)\n",
    "    elif \"resnext101_32x8d_wsl\" in checkpoint_path:\n",
    "        net = torch.hub.load(\"facebookresearch/WSL-Images\", \"resnext101_32x8d_wsl\")\n",
    "    elif \"efficientnet_b0\" in checkpoint_path:\n",
    "        net = getattr(timm.models.efficientnet, \"efficientnet_b0\")(pretrained=False)\n",
    "    elif \"densenet121\" in checkpoint_path:\n",
    "        net = timm.models.densenet121(pretrained=False)\n",
    "    else:\n",
    "        raise ValueError(\"Unexpected checkpont name: %s\" % checkpoint_path)\n",
    "    net = add_tail(net, num_classes)\n",
    "    dummy_device = torch.device(\"cpu\")\n",
    "    d = torch.load(checkpoint_path, map_location=dummy_device)\n",
    "    for key in list(d.keys()):\n",
    "        d[key.replace(\"model.\", \"\")] = d.pop(key)\n",
    "    net.load_state_dict(d)\n",
    "    net = net.to(DEVICE)\n",
    "    net = net.eval()\n",
    "    return net\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def predict(net, criterion, val_laoder):\n",
    "    net.eval()\n",
    "    records = []\n",
    "    val_laoder = tqdm(val_laoder, leave=False, total=len(val_laoder))\n",
    "    for icount, (xb, filename, seconds) in enumerate(val_laoder):\n",
    "        xb = xb.to(DEVICE)\n",
    "        prob = net(xb)\n",
    "        prob = torch.sigmoid(prob)\n",
    "        records.append({\n",
    "            \"prob\": prob,\n",
    "            \"filename\": filename,\n",
    "            \"seconds\": seconds\n",
    "        })\n",
    "    return records\n",
    "\n",
    "\n",
    "def one_fold(checkpoint_path, fold, train_set, val_set, epochs=20, save=True, save_root=None):\n",
    "    net = load_net(checkpoint_path)\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    val_data = BirdClefDataset(\n",
    "        meta=df.iloc[val_set].reset_index(drop=True),\n",
    "        sr=SR,\n",
    "        duration=DURATION,\n",
    "        is_train=False\n",
    "    )\n",
    "    val_laoder = DataLoader(val_data, batch_size=VAL_BATCH_SIZE, num_workers=VAL_NUM_WORKERS, shuffle=False)\n",
    "    y_preda = predict(net, criterion, val_laoder)\n",
    "    return y_preda\n",
    "\n",
    "\n",
    "def predict_for_oof(checkpoint_path, epochs=20, save=True, n_splits=5, seed=177, save_root=None, suffix=\"\", folds=None):\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    fold_bar = tqdm(df.reset_index().groupby(\"fold\").index.apply(list).items(), total=df.fold.max() + 1)\n",
    "\n",
    "    for fold, val_set in fold_bar:\n",
    "        if folds and not fold in folds:\n",
    "            continue\n",
    "\n",
    "        print(f\"\\n############################### [FOLD {fold}]\")\n",
    "        fold_bar.set_description(f\"[FOLD {fold}]\")\n",
    "        train_set = np.setdiff1d(df.index, val_set)\n",
    "        records = one_fold(checkpoint_path, fold=fold, train_set=train_set, val_set=val_set, epochs=epochs, save=save,\n",
    "                           save_root=save_root)\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "        return records\n",
    "\n",
    "\n",
    "def to_call_prob(row):\n",
    "    i = row[\"seconds\"] // DURATION\n",
    "    call_prob = float(row[\"nocalldetection\"].split()[i])\n",
    "    return call_prob\n",
    "\n",
    "\n",
    "def to_birds(row):\n",
    "    if row[\"call_prob\"] < 0.5:\n",
    "        return \"nocall\"\n",
    "    res = [row[\"primary_label\"]] + eval(row[\"secondary_labels\"])\n",
    "    return \" \".join(res)\n",
    "\n",
    "\n",
    "INV_LABEL_IDS = {v: k for k, v in LABEL_IDS.items()}\n",
    "columns = [INV_LABEL_IDS[i] for i in range(len(LABEL_IDS))]\n",
    "metadata_df = pd.read_csv(\"../input/birdclef-2021/train_metadata.csv\")\n",
    "nocall_df = pd.read_csv(\n",
    "    \"../input/train-short-audio-nocall-fold0to4/train_short_audio_nocall_fold0to4/nocalldetection_for_shortaudio_fold0.csv\")\n",
    "\n",
    "import glob\n",
    "\n",
    "filename_to_nocalldetection = {}\n",
    "filepath_list = list(\n",
    "    glob.glob(\"../generated/train-short-audio-nocall-fold0to4/train_short_audio_nocall_fold0to4/*.csv\"))\n",
    "for filepath in filepath_list:\n",
    "    nocall_df = pd.read_csv(filepath)\n",
    "    probs = nocall_df[\"nocalldetection\"].apply(\n",
    "        lambda _: list(\n",
    "            map(float, _.split())\n",
    "        )\n",
    "    ).tolist()\n",
    "    for k, v in zip(nocall_df[\"filename\"].tolist(), probs):\n",
    "        if not k in filename_to_nocalldetection:\n",
    "            filename_to_nocalldetection[k] = v\n",
    "        else:\n",
    "            w = filename_to_nocalldetection[k]\n",
    "            for i in range(len(w)):\n",
    "                w[i] += v[i]\n",
    "            filename_to_nocalldetection[k] = w\n",
    "\n",
    "for k, v in filename_to_nocalldetection.items():\n",
    "    for i in range(len(v)):\n",
    "        filename_to_nocalldetection[k][i] /= len(filepath_list)\n",
    "\n",
    "for k, v in filename_to_nocalldetection.items():\n",
    "    filename_to_nocalldetection[k] = \" \".join(map(str, v))\n",
    "\n",
    "nocall_df = pd.DataFrame(filename_to_nocalldetection.items(), columns=[\"filename\", \"nocalldetection\"])\n",
    "\n",
    "nocall_df.head()\n",
    "\n",
    "filepath_list = []\n",
    "for checkpoint_path in checkpoint_paths:\n",
    "    print(\"\\n\\n###########################################\", checkpoint_path)\n",
    "    # Find out which fold it is from the name of the model file.\n",
    "    fold = -1\n",
    "    for i in range(5):\n",
    "        if f\"fold{i}\" in checkpoint_path.stem:\n",
    "            fold = i\n",
    "            break\n",
    "    print(\"target validation fold is %d\" % fold)\n",
    "    if fold == -1:\n",
    "        raise ValueError(\"Unexpected fold value\")\n",
    "    # Run on the fold that is the target of oof.\n",
    "    records_list = predict_for_oof(checkpoint_path.as_posix(), epochs=config.epochs, suffix=config.suffix, folds=[fold])\n",
    "    dfs = []\n",
    "    for records in records_list:\n",
    "        prob = records[\"prob\"].to(\"cpu\").numpy()\n",
    "        _df = pd.DataFrame(prob)\n",
    "        _df.columns = columns\n",
    "        _df[\"seconds\"] = records[\"seconds\"].to(\"cpu\").numpy().tolist()\n",
    "        _df[\"filename\"] = list(records[\"filename\"])\n",
    "        dfs.append(_df)\n",
    "    oof_df = pd.concat(dfs)\n",
    "    oof_df = pd.merge(oof_df, metadata_df, how=\"left\", on=[\"filename\"])\n",
    "    oof_df = pd.merge(oof_df, nocall_df[[\"filename\", \"nocalldetection\"]], how=\"left\", on=[\"filename\"])\n",
    "    oof_df[\"call_prob\"] = oof_df.apply(to_call_prob, axis=1)\n",
    "    oof_df[\"birds\"] = oof_df.apply(to_birds, axis=1)\n",
    "    filepath = \"%s.csv\" % checkpoint_path.stem\n",
    "    print(f\"Save to {filepath}\")\n",
    "    oof_df.drop(\n",
    "        columns=[\n",
    "            'scientific_name',\n",
    "            'common_name',\n",
    "            'license',\n",
    "            'time',\n",
    "            'url',\n",
    "            'nocalldetection',\n",
    "        ]\n",
    "    ).to_csv(filepath, index=False)\n",
    "    filepath_list.append(filepath)\n",
    "\n",
    "oof_df.drop(\n",
    "    columns=[\n",
    "        'scientific_name',\n",
    "        'common_name',\n",
    "        'license',\n",
    "        'time',\n",
    "        'url',\n",
    "        'nocalldetection',\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c90e49-a109-4045-ade9-ee508a22819e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install -q --use-feature= in -tree-build \"../generated/resnest50-fast-package/resnest-0.0.6b20200701/resnest\"\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "LABELS_PROBABILITY_DIR = \"../output/06_stage3/labels_probability/\"\n",
    "LGBM_PKL_DIR = \"../output/06_stage3/lgbm_pkl/\"\n",
    "\n",
    "import os\n",
    "\n",
    "if not os.path.exists(LABELS_PROBABILITY_DIR):\n",
    "    os.mkdir(LABELS_PROBABILITY_DIR)\n",
    "if not os.path.exists(LGBM_PKL_DIR):\n",
    "    os.mkdir(LGBM_PKL_DIR)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "import re\n",
    "import time\n",
    "\n",
    "import pickle\n",
    "from typing import List\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# sound\n",
    "import librosa as lb\n",
    "import soundfile as sf\n",
    "\n",
    "# pytorch\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from resnest.torch import resnest50\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score\n",
    "import xgboost as xgb\n",
    "import pickle\n",
    "from catboost import CatBoostClassifier\n",
    "from catboost import Pool\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "import lightgbm as lgb\n",
    "import random\n",
    "\n",
    "BIRD_LIST = sorted(os.listdir('../input/birdclef-2021/train_short_audio'))\n",
    "BIRD2IDX = {bird: idx for idx, bird in enumerate(BIRD_LIST)}\n",
    "BIRD2IDX['nocall'] = -1\n",
    "IDX2BIRD = {idx: bird for bird, idx in BIRD2IDX.items()}\n",
    "\n",
    "# 10 frame version\n",
    "filepath_list = [\n",
    "    \"../generated/metadata-probability-v0525-2100/birdclef_resnest50_fold1_epoch_34_f1_val_04757_20210524185455.csv\"\n",
    "]\n",
    "prob_df = pd.concat([pd.read_csv(_) for _ in filepath_list])\n",
    "\n",
    "\n",
    "class TrainingConfig:\n",
    "    def __init__(self):\n",
    "        self.nocall_threshold: float = 0.5\n",
    "        self.num_kfolds: int = 5\n",
    "        self.num_spieces: int = 397\n",
    "        self.num_candidates: int = 5\n",
    "        self.max_distance: int = 15  # 20\n",
    "        self.sampling_strategy: float = None  # 1.0\n",
    "        self.random_state: int = 777\n",
    "        self.num_prob: int = 6\n",
    "        self.use_to_birds = True\n",
    "        self.weights_filepath_dict = {\n",
    "            'lgbm': [(LGBM_PKL_DIR + f\"lgbm_{kfold_index}.pkl\") for kfold_index in range(self.num_kfolds)],\n",
    "        }\n",
    "\n",
    "\n",
    "training_config = TrainingConfig()\n",
    "\n",
    "\n",
    "class Config:\n",
    "    def __init__(self):\n",
    "        self.num_kfolds: int = training_config.num_kfolds\n",
    "        self.num_spieces: int = training_config.num_spieces\n",
    "        self.num_candidates: int = training_config.num_candidates\n",
    "        self.max_distance: int = training_config.max_distance\n",
    "        self.nocall_threshold: float = training_config.nocall_threshold\n",
    "        self.num_prob: int = training_config.num_prob\n",
    "        # check F1 score without 3rd stage(table competition) \n",
    "        self.check_baseline: bool = True\n",
    "        # List of file paths of the models which are used when determining if the bird is acceptable.\n",
    "        self.weights_filepath_dict = training_config.weights_filepath_dict\n",
    "        # Weights for the models to predict the probability of each bird singing for each frame.\n",
    "        self.checkpoint_paths = [\n",
    "            Path(\"../generated/clefmodel/birdclef_resnest50_fold0_epoch_27_f1_val_05179_20210520120053.pth\"),  # id36\n",
    "            Path(\"../generated/clefmodel/birdclef_resnest50_fold0_epoch_13_f1_val_03502_20210522050604.pth\"),  # id51\n",
    "            Path(\n",
    "                \"../generated/birdclef-groupby-author-05221040-728258/birdclef_resnest50_fold0_epoch_33_f1_val_03859_20210524151554.pth\"),\n",
    "            # id58\n",
    "            Path(\n",
    "                \"../generated/birdclef-groupby-author-05221040-728258/birdclef_resnest50_fold1_epoch_34_f1_val_04757_20210524185455.pth\"),\n",
    "            # id59\n",
    "            Path(\n",
    "                \"../generated/birdclef-groupby-author-05221040-728258/birdclef_resnest50_fold2_epoch_34_f1_val_05027_20210524223209.pth\"),\n",
    "            # id60\n",
    "            Path(\n",
    "                \"../generated/birdclef-groupby-author-05221040-728258/birdclef_resnest50_fold3_epoch_20_f1_val_04299_20210525010703.pth\"),\n",
    "            # id61\n",
    "            Path(\n",
    "                \"../generated/birdclef-groupby-author-05221040-728258/birdclef_resnest50_fold4_epoch_34_f1_val_05140_20210525074929.pth\"),\n",
    "            # id62\n",
    "            Path(\n",
    "                \"../generated/clefmodel/resnest50_sr32000_d7_miixup-5.0_2ndlw-0.6_grouped-by-auther/birdclef_resnest50_fold0_epoch_78_f1_val_03658_20210528221629.pth\"),\n",
    "            # id97\n",
    "            Path(\n",
    "                \"../generated/clefmodel/resnest50_sr32000_d7_miixup-5.0_2ndlw-0.6_grouped-by-auther/birdclef_resnest50_fold0_epoch_84_f1_val_03689_20210528225810.pth\"),\n",
    "            # id97\n",
    "            Path(\n",
    "                \"../generated/clefmodel/resnest50_sr32000_d7_miixup-5.0_2ndlw-0.6_grouped-by-auther/birdclef_resnest50_fold1_epoch_27_f1_val_03942_20210529062427.pth\"),\n",
    "            # id98\n",
    "        ]\n",
    "        # call probability of each bird for each sample used for candidate extraction (cache)\n",
    "        self.pred_filepath_list = [\n",
    "            self.get_prob_filepath_from_checkpoint(path) for path in self.checkpoint_paths\n",
    "        ]\n",
    "\n",
    "    def get_prob_filepath_from_checkpoint(self, checkpoint_path: Path) -> str:\n",
    "        return LABELS_PROBABILITY_DIR + \"train_soundscape_labels_probabilitiy_\" + checkpoint_path.stem + \".csv\"\n",
    "\n",
    "\n",
    "config = Config()\n",
    "\n",
    "\n",
    "def get_locations():\n",
    "    return [{\n",
    "        \"site\": \"COL\",\n",
    "        \"latitude\": 5.57,\n",
    "        \"longitude\": -75.85\n",
    "    }, {\n",
    "        \"site\": \"COR\",\n",
    "        \"latitude\": 10.12,\n",
    "        \"longitude\": -84.51\n",
    "    }, {\n",
    "        \"site\": \"SNE\",\n",
    "        \"latitude\": 38.49,\n",
    "        \"longitude\": -119.95\n",
    "    }, {\n",
    "        \"site\": \"SSW\",\n",
    "        \"latitude\": 42.47,\n",
    "        \"longitude\": -76.45\n",
    "    }]\n",
    "\n",
    "\n",
    "def to_site(row, max_distance: int):\n",
    "    best = max_distance\n",
    "    answer = \"Other\"\n",
    "    for location in get_locations():\n",
    "        x = (row[\"latitude\"] - location[\"latitude\"])\n",
    "        y = (row[\"longitude\"] - location[\"longitude\"])\n",
    "        dist = (x ** 2 + y ** 2) ** 0.5\n",
    "        if dist < best:\n",
    "            best = dist\n",
    "            answer = location[\"site\"]\n",
    "    return answer\n",
    "\n",
    "\n",
    "def to_latitude(site: str) -> str:\n",
    "    for location in get_locations():\n",
    "        if site == location[\"site\"]:\n",
    "            return location[\"latitude\"]\n",
    "    return -10000\n",
    "\n",
    "\n",
    "def to_longitude(site: str) -> str:\n",
    "    for location in get_locations():\n",
    "        if site == location[\"site\"]:\n",
    "            return location[\"longitude\"]\n",
    "    return -10000\n",
    "\n",
    "\n",
    "def to_birds(row, th: float) -> str:\n",
    "    if row[\"call_prob\"] < th:\n",
    "        return \"nocall\"\n",
    "    res = [row[\"primary_label\"]] + eval(row[\"secondary_labels\"])\n",
    "    return \" \".join(res)\n",
    "\n",
    "\n",
    "def make_candidates(\n",
    "        prob_df: pd.DataFrame,\n",
    "        num_spieces: int,\n",
    "        num_candidates: int,\n",
    "        max_distance: int,\n",
    "        num_prob: int = 6,  # number of frames to be allocated for front and rear (if 3, then 3 for front, 3 for rear)\n",
    "        nocall_threshold: float = 0.5,\n",
    "):\n",
    "    if \"author\" in prob_df.columns:  # meta data (train_short_audio)\n",
    "        prob_df[\"birds\"] = prob_df.apply(\n",
    "            lambda row: to_birds(row, th=nocall_threshold),\n",
    "            axis=1\n",
    "        )\n",
    "        print(\"Candidate nocall ratio: %.4f\" % (prob_df[\"birds\"] == \"nocall\").mean())\n",
    "        prob_df[\"audio_id\"] = prob_df[\"filename\"].apply(\n",
    "            lambda _: int(_.replace(\"XC\", \"\").replace(\".ogg\", \"\"))\n",
    "        )\n",
    "        prob_df[\"row_id\"] = prob_df.apply(\n",
    "            lambda row: \"%s_%s\" % (row[\"audio_id\"], row[\"seconds\"]),\n",
    "            axis=1\n",
    "        )\n",
    "        prob_df[\"year\"] = prob_df[\"date\"].apply(lambda _: int(_.split(\"-\")[0]))\n",
    "        prob_df[\"month\"] = prob_df[\"date\"].apply(lambda _: int(_.split(\"-\")[1]))\n",
    "        prob_df[\"site\"] = prob_df.apply(\n",
    "            lambda row: to_site(row, max_distance),\n",
    "            axis=1\n",
    "        )\n",
    "    else:\n",
    "        prob_df[\"year\"] = prob_df[\"date\"].apply(lambda _: int(str(_)[:4]))\n",
    "        prob_df[\"month\"] = prob_df[\"date\"].apply(lambda _: int(str(_)[4:6]))\n",
    "        prob_df[\"latitude\"] = prob_df[\"site\"].apply(to_latitude)\n",
    "        prob_df[\"longitude\"] = prob_df[\"site\"].apply(to_longitude)\n",
    "\n",
    "    sum_prob_list = prob_df[BIRD_LIST].sum(axis=1).tolist()\n",
    "    mean_prob_list = prob_df[BIRD_LIST].mean(axis=1).tolist()\n",
    "    std_prob_list = prob_df[BIRD_LIST].std(axis=1).tolist()\n",
    "    max_prob_list = prob_df[BIRD_LIST].max(axis=1).tolist()\n",
    "    min_prob_list = prob_df[BIRD_LIST].min(axis=1).tolist()\n",
    "    skew_prob_list = prob_df[BIRD_LIST].skew(axis=1).tolist()\n",
    "    kurt_prob_list = prob_df[BIRD_LIST].kurt(axis=1).tolist()\n",
    "\n",
    "    X = prob_df[BIRD_LIST].values\n",
    "    bird_ids_list = np.argsort(-X)[:, :num_candidates]\n",
    "    row_ids = prob_df[\"row_id\"].tolist()\n",
    "    rows = [i // num_candidates for i in range(len(bird_ids_list.flatten()))]\n",
    "    cols = bird_ids_list.flatten()\n",
    "    # What number?\n",
    "    ranks = [i % num_candidates for i in range(len(rows))]\n",
    "    probs_list = X[rows, cols]\n",
    "    D = {\n",
    "        \"row_id\": [row_ids[i] for i in rows],\n",
    "        \"rank\": ranks,\n",
    "        \"bird_id\": bird_ids_list.flatten(),\n",
    "        \"prob\": probs_list.flatten(),\n",
    "        \"sum_prob\": [sum_prob_list[i // num_candidates] for i in range(num_candidates * len(mean_prob_list))],\n",
    "        \"mean_prob\": [mean_prob_list[i // num_candidates] for i in range(num_candidates * len(mean_prob_list))],\n",
    "        \"std_prob\": [std_prob_list[i // num_candidates] for i in range(num_candidates * len(std_prob_list))],\n",
    "        \"max_prob\": [max_prob_list[i // num_candidates] for i in range(num_candidates * len(max_prob_list))],\n",
    "        \"min_prob\": [min_prob_list[i // num_candidates] for i in range(num_candidates * len(min_prob_list))],\n",
    "        \"skew_prob\": [skew_prob_list[i // num_candidates] for i in range(num_candidates * len(skew_prob_list))],\n",
    "        \"kurt_prob\": [kurt_prob_list[i // num_candidates] for i in range(num_candidates * len(kurt_prob_list))],\n",
    "    }\n",
    "    audio_ids = prob_df[\"audio_id\"].values[rows]\n",
    "    for diff in range(-num_prob, num_prob + 1):\n",
    "        if diff == 0:\n",
    "            continue\n",
    "        neighbor_audio_ids = prob_df[\"audio_id\"].shift(diff).values[rows]\n",
    "        Y = prob_df[BIRD_LIST].shift(diff).values\n",
    "        c = f\"next{abs(diff)}_prob\" if diff < 0 else f\"prev{diff}_prob\"\n",
    "        c = c.replace(\"1_prob\", \"_prob\")  # Fix next1_prob to next_prob\n",
    "        v = Y[rows, cols].flatten()\n",
    "        v[audio_ids != neighbor_audio_ids] = np.nan\n",
    "        D[c] = v\n",
    "\n",
    "    candidate_df = pd.DataFrame(D)\n",
    "    columns = [\n",
    "        \"row_id\",\n",
    "        \"site\",\n",
    "        \"year\",\n",
    "        \"month\",\n",
    "        \"audio_id\",\n",
    "        \"seconds\",\n",
    "        \"birds\",\n",
    "    ]\n",
    "    candidate_df = pd.merge(\n",
    "        candidate_df,\n",
    "        prob_df[columns],\n",
    "        how=\"left\",\n",
    "        on=\"row_id\"\n",
    "    )\n",
    "    candidate_df[\"target\"] = candidate_df.apply(\n",
    "        lambda row: IDX2BIRD[row[\"bird_id\"]] in set(row[\"birds\"].split()),\n",
    "        axis=1\n",
    "    )\n",
    "    candidate_df[\"label\"] = candidate_df[\"bird_id\"].map(IDX2BIRD)\n",
    "    return candidate_df\n",
    "\n",
    "\n",
    "def load_metadata():\n",
    "    meta_df = pd.read_csv(\"../input/birdclef-2021/train_metadata.csv\")\n",
    "    meta_df[\"id\"] = meta_df.index + 1\n",
    "    meta_df[\"year\"] = meta_df[\"date\"].apply(lambda _: _.split(\"-\")[0]).astype(int)\n",
    "    meta_df[\"month\"] = meta_df[\"date\"].apply(lambda _: _.split(\"-\")[1]).astype(int)\n",
    "    return meta_df\n",
    "\n",
    "\n",
    "def to_zscore(row):\n",
    "    x = row[\"prob\"]\n",
    "    mu = row[\"prob_avg_in_same_audio\"]\n",
    "    sigma = row[\"prob_var_in_same_audio\"] ** 0.5\n",
    "    if sigma < 1e-6:\n",
    "        return 0\n",
    "    else:\n",
    "        return (x - mu) / sigma\n",
    "\n",
    "\n",
    "def add_same_audio_features(\n",
    "        candidate_df: pd.DataFrame,\n",
    "        df: pd.DataFrame\n",
    "):\n",
    "    # Average probability per bird in the same audio\n",
    "    _gdf = df.groupby([\"audio_id\"], as_index=False).mean()[[\"audio_id\"] + BIRD_LIST]\n",
    "    _df = pd.melt(\n",
    "        _gdf,\n",
    "        id_vars=[\"audio_id\"]\n",
    "    ).rename(columns={\n",
    "        \"variable\": \"label\",\n",
    "        \"value\": \"prob_avg_in_same_audio\"\n",
    "    })\n",
    "    candidate_df = pd.merge(candidate_df, _df, how=\"left\", on=[\"audio_id\", \"label\"])\n",
    "    # Maximum value for each bird in the same audio\n",
    "    _gdf = df.groupby([\"audio_id\"], as_index=False).max()[[\"audio_id\"] + BIRD_LIST]\n",
    "    _df = pd.melt(\n",
    "        _gdf,\n",
    "        id_vars=[\"audio_id\"]\n",
    "    ).rename(columns={\n",
    "        \"variable\": \"label\",\n",
    "        \"value\": \"prob_max_in_same_audio\"\n",
    "    })\n",
    "    candidate_df = pd.merge(candidate_df, _df, how=\"left\", on=[\"audio_id\", \"label\"])\n",
    "    # Variance of each bird in the same audio\n",
    "    _gdf = df.groupby([\"audio_id\"], as_index=False).var()[[\"audio_id\"] + BIRD_LIST]\n",
    "    _df = pd.melt(\n",
    "        _gdf,\n",
    "        id_vars=[\"audio_id\"]\n",
    "    ).rename(columns={\n",
    "        \"variable\": \"label\",\n",
    "        \"value\": \"prob_var_in_same_audio\"\n",
    "    })\n",
    "    candidate_df = pd.merge(candidate_df, _df, how=\"left\", on=[\"audio_id\", \"label\"])\n",
    "    candidate_df[\"zscore_in_same_audio\"] = candidate_df.apply(to_zscore, axis=1)\n",
    "    return candidate_df\n",
    "\n",
    "\n",
    "def add_features(\n",
    "        candidate_df: pd.DataFrame,\n",
    "        df: pd.DataFrame,\n",
    "        max_distance: int,\n",
    "):\n",
    "    meta_df = load_metadata()\n",
    "    # latitude & longitude\n",
    "    if not \"latitude\" in candidate_df.columns:\n",
    "        candidate_df[\"latitude\"] = candidate_df[\"site\"].apply(to_latitude)\n",
    "    if not \"longitude\" in candidate_df.columns:\n",
    "        candidate_df[\"longitude\"] = candidate_df[\"site\"].apply(to_longitude)\n",
    "    # Number of Appearances\n",
    "    candidate_df[\"num_appear\"] = candidate_df[\"label\"].map(\n",
    "        meta_df[\"primary_label\"].value_counts()\n",
    "    )\n",
    "    meta_df[\"site\"] = meta_df.apply(\n",
    "        lambda row: to_site(\n",
    "            row,\n",
    "            max_distance=max_distance\n",
    "        ),\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    # Number of occurrences by region\n",
    "    _df = meta_df.groupby(\n",
    "        [\"primary_label\", \"site\"],\n",
    "        as_index=False\n",
    "    )[\"id\"].count().rename(\n",
    "        columns={\n",
    "            \"primary_label\": \"label\",\n",
    "            \"id\": \"site_num_appear\"\n",
    "        }\n",
    "    )\n",
    "    candidate_df = pd.merge(\n",
    "        candidate_df,\n",
    "        _df,\n",
    "        how=\"left\",\n",
    "        on=[\"label\", \"site\"]\n",
    "    )\n",
    "    candidate_df[\"site_appear_ratio\"] = candidate_df[\"site_num_appear\"] / candidate_df[\"num_appear\"]\n",
    "    # Seasonal statistics\n",
    "    _df = meta_df.groupby(\n",
    "        [\"primary_label\", \"month\"],\n",
    "        as_index=False\n",
    "    )[\"id\"].count().rename(\n",
    "        columns={\n",
    "            \"primary_label\": \"label\",\n",
    "            \"id\": \"month_num_appear\"\n",
    "        }\n",
    "    )\n",
    "    candidate_df = pd.merge(candidate_df, _df, how=\"left\", on=[\"label\", \"month\"])\n",
    "    candidate_df[\"month_appear_ratio\"] = candidate_df[\"month_num_appear\"] / candidate_df[\"num_appear\"]\n",
    "\n",
    "    candidate_df = add_same_audio_features(candidate_df, df)\n",
    "\n",
    "    # Correction of probability (all down)\n",
    "    candidate_df[\"prob / num_appear\"] = candidate_df[\"prob\"] / (candidate_df[\"num_appear\"].fillna(0) + 1)\n",
    "    candidate_df[\"prob / site_num_appear\"] = candidate_df[\"prob\"] / (candidate_df[\"site_num_appear\"].fillna(0) + 1)\n",
    "    candidate_df[\"prob * site_appear_ratio\"] = candidate_df[\"prob\"] * (\n",
    "                candidate_df[\"site_appear_ratio\"].fillna(0) + 0.001)\n",
    "\n",
    "    # Amount of change from the previous and following frames\n",
    "    candidate_df[\"prob_avg\"] = candidate_df[[\"prev_prob\", \"prob\", \"next_prob\"]].mean(axis=1)\n",
    "    candidate_df[\"prob_diff\"] = candidate_df[\"prob\"] - candidate_df[\"prob_avg\"]\n",
    "    candidate_df[\"prob - prob_max_in_same_audio\"] = candidate_df[\"prob\"] - candidate_df[\"prob_max_in_same_audio\"]\n",
    "\n",
    "    # Average of back and forward frames\n",
    "\n",
    "    return candidate_df\n",
    "\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"DEVICE:\", DEVICE)\n",
    "\n",
    "\n",
    "class MelSpecComputer:\n",
    "    def __init__(self, sr, n_mels, fmin, fmax, **kwargs):\n",
    "        self.sr = sr\n",
    "        self.n_mels = n_mels\n",
    "        self.fmin = fmin\n",
    "        self.fmax = fmax\n",
    "        kwargs[\"n_fft\"] = kwargs.get(\"n_fft\", self.sr // 10)\n",
    "        kwargs[\"hop_length\"] = kwargs.get(\"hop_length\", self.sr // (10 * 4))\n",
    "        self.kwargs = kwargs\n",
    "\n",
    "    def __call__(self, y):\n",
    "        melspec = lb.feature.melspectrogram(\n",
    "            y, sr=self.sr, n_mels=self.n_mels, fmin=self.fmin, fmax=self.fmax, **self.kwargs,\n",
    "        )\n",
    "\n",
    "        melspec = lb.power_to_db(melspec).astype(np.float32)\n",
    "        return melspec\n",
    "\n",
    "\n",
    "def mono_to_color(X, eps=1e-6, mean=None, std=None):\n",
    "    mean = mean or X.mean()\n",
    "    std = std or X.std()\n",
    "    X = (X - mean) / (std + eps)\n",
    "\n",
    "    _min, _max = X.min(), X.max()\n",
    "\n",
    "    if (_max - _min) > eps:\n",
    "        V = np.clip(X, _min, _max)\n",
    "        V = 255 * (V - _min) / (_max - _min)\n",
    "        V = V.astype(np.uint8)\n",
    "    else:\n",
    "        V = np.zeros_like(X, dtype=np.uint8)\n",
    "\n",
    "    return V\n",
    "\n",
    "\n",
    "def crop_or_pad(y, length):\n",
    "    if len(y) < length:\n",
    "        y = np.concatenate([y, length - np.zeros(len(y))])\n",
    "    elif len(y) > length:\n",
    "        y = y[:length]\n",
    "    return y\n",
    "\n",
    "\n",
    "class BirdCLEFDataset(Dataset):\n",
    "    def __init__(self, data, sr=32_000, n_mels=128, fmin=0, fmax=None, duration=5, step=None, res_type=\"kaiser_fast\",\n",
    "                 resample=True):\n",
    "\n",
    "        self.data = data\n",
    "\n",
    "        self.sr = sr\n",
    "        self.n_mels = n_mels\n",
    "        self.fmin = fmin\n",
    "        self.fmax = fmax or self.sr // 2\n",
    "\n",
    "        self.duration = duration\n",
    "        self.audio_length = self.duration * self.sr\n",
    "        self.step = step or self.audio_length\n",
    "\n",
    "        self.res_type = res_type\n",
    "        self.resample = resample\n",
    "\n",
    "        self.mel_spec_computer = MelSpecComputer(\n",
    "            sr=self.sr,\n",
    "            n_mels=self.n_mels,\n",
    "            fmin=self.fmin,\n",
    "            fmax=self.fmax\n",
    "        )\n",
    "        self.npy_save_root = Path(\"../output/06_stage3/birdclef_dataset\")\n",
    "\n",
    "        os.makedirs(self.npy_save_root, exist_ok=True)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    @staticmethod\n",
    "    def normalize(image):\n",
    "        image = image.astype(\"float32\", copy=False) / 255.0\n",
    "        image = np.stack([image, image, image])\n",
    "        return image\n",
    "\n",
    "    def audio_to_image(self, audio):\n",
    "        melspec = self.mel_spec_computer(audio)\n",
    "        image = mono_to_color(melspec)\n",
    "        image = self.normalize(image)\n",
    "        return image\n",
    "\n",
    "    def read_file(self, filepath):\n",
    "        filename = filepath.stem\n",
    "        npy_path = self.npy_save_root / f\"{filename}.npy\"\n",
    "\n",
    "        if not os.path.exists(npy_path):\n",
    "            audio, orig_sr = sf.read(filepath, dtype=\"float32\")\n",
    "\n",
    "            if self.resample and orig_sr != self.sr:\n",
    "                audio = lb.resample(audio, orig_sr, self.sr, res_type=self.res_type)\n",
    "\n",
    "            audios = []\n",
    "            for i in range(self.audio_length, len(audio) + self.step, self.step):\n",
    "                start = max(0, i - self.audio_length)\n",
    "                end = start + self.audio_length\n",
    "                audios.append(audio[start:end])\n",
    "\n",
    "            if len(audios[-1]) < self.audio_length:\n",
    "                audios = audios[:-1]\n",
    "\n",
    "            images = [self.audio_to_image(audio) for audio in audios]\n",
    "            images = np.stack(images)\n",
    "\n",
    "            np.save(str(npy_path), images)\n",
    "        return np.load(npy_path)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.read_file(self.data.loc[idx, \"filepath\"])\n",
    "\n",
    "\n",
    "def load_net(checkpoint_path, num_classes=397):\n",
    "    net = resnest50(pretrained=False)\n",
    "    net.fc = nn.Linear(net.fc.in_features, num_classes)\n",
    "    dummy_device = torch.device(\"cpu\")\n",
    "    d = torch.load(checkpoint_path, map_location=dummy_device)\n",
    "    for key in list(d.keys()):\n",
    "        d[key.replace(\"model.\", \"\")] = d.pop(key)\n",
    "    net.load_state_dict(d)\n",
    "    net = net.to(DEVICE)\n",
    "    net = net.eval()\n",
    "    return net\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def get_thresh_preds(out, thresh=None):\n",
    "    thresh = thresh or THRESH\n",
    "    o = (-out).argsort(1)\n",
    "    npreds = (out > thresh).sum(1)\n",
    "    preds = []\n",
    "    for oo, npred in zip(o, npreds):\n",
    "        preds.append(oo[:npred].cpu().numpy().tolist())\n",
    "    return preds\n",
    "\n",
    "\n",
    "def predict(nets, test_data, names=True):\n",
    "    preds = []\n",
    "    with torch.no_grad():\n",
    "        for idx in tqdm(list(range(len(test_data)))):\n",
    "            xb = torch.from_numpy(test_data[idx]).to(DEVICE)\n",
    "            pred = 0.\n",
    "            for net in nets:\n",
    "                o = net(xb)\n",
    "                o = torch.sigmoid(o)\n",
    "                pred += o\n",
    "            pred /= len(nets)\n",
    "            if names:\n",
    "                pred = BIRD_LIST(get_thresh_preds(pred))\n",
    "\n",
    "            preds.append(pred)\n",
    "    return preds\n",
    "\n",
    "\n",
    "def get_prob_df(config, audio_paths):\n",
    "    data = pd.DataFrame(\n",
    "        [(path.stem, *path.stem.split(\"_\"), path) for path in Path(audio_paths).glob(\"*.ogg\")],\n",
    "        columns=[\"filename\", \"id\", \"site\", \"date\", \"filepath\"]\n",
    "    )\n",
    "    test_data = BirdCLEFDataset(data=data)\n",
    "\n",
    "    for checkpoint_path in config.checkpoint_paths:\n",
    "        prob_filepath = config.get_prob_filepath_from_checkpoint(checkpoint_path)\n",
    "        if (not os.path.exists(prob_filepath)) or (\n",
    "                TARGET_PATH is None):  # Always calculate when no cash is available or when submitting.\n",
    "            nets = [load_net(checkpoint_path.as_posix())]\n",
    "            pred_probas = predict(nets, test_data, names=False)\n",
    "            if TARGET_PATH:  # local\n",
    "                df = pd.read_csv(TARGET_PATH, usecols=[\"row_id\", \"birds\"])\n",
    "            else:  # when it is submission\n",
    "                if str(audio_paths) == \"../input/birdclef-2021/train_soundscapes\":\n",
    "                    print(audio_paths)\n",
    "                    df = pd.read_csv(Path(\"../input/birdclef-2021/train_soundscape_labels.csv\"),\n",
    "                                     usecols=[\"row_id\", \"birds\"])\n",
    "                else:\n",
    "                    print(SAMPLE_SUB_PATH)\n",
    "                    df = pd.read_csv(SAMPLE_SUB_PATH, usecols=[\"row_id\", \"birds\"])\n",
    "            df[\"audio_id\"] = df[\"row_id\"].apply(lambda _: int(_.split(\"_\")[0]))\n",
    "            df[\"site\"] = df[\"row_id\"].apply(lambda _: _.split(\"_\")[1])\n",
    "            df[\"seconds\"] = df[\"row_id\"].apply(lambda _: int(_.split(\"_\")[2]))\n",
    "            assert len(data) == len(pred_probas)\n",
    "            n = len(data)\n",
    "            audio_id_to_date = {}\n",
    "            audio_id_to_site = {}\n",
    "            for filepath in audio_paths.glob(\"*.ogg\"):\n",
    "                audio_id, site, date = os.path.basename(filepath).replace(\".ogg\", \"\").split(\"_\")\n",
    "                audio_id = int(audio_id)\n",
    "                audio_id_to_date[audio_id] = date\n",
    "                audio_id_to_site[audio_id] = site\n",
    "            dfs = []\n",
    "            for i in range(n):\n",
    "                row = data.iloc[i]\n",
    "                audio_id = int(row[\"id\"])\n",
    "                pred = pred_probas[i]\n",
    "                _df = pd.DataFrame(pred.to(\"cpu\").numpy())\n",
    "                _df.columns = [IDX2BIRD[j] for j in range(_df.shape[1])]\n",
    "                _df[\"audio_id\"] = audio_id\n",
    "                _df[\"date\"] = audio_id_to_date[audio_id]\n",
    "                _df[\"site\"] = audio_id_to_site[audio_id]\n",
    "                _df[\"seconds\"] = [(j + 1) * 5 for j in range(120)]\n",
    "                dfs.append(_df)\n",
    "            prob_df = pd.concat(dfs)\n",
    "            prob_df = pd.merge(prob_df, df, how=\"left\", on=[\"site\", \"audio_id\", \"seconds\"])\n",
    "            print(f\"Save to {prob_filepath}\")\n",
    "            prob_df.to_csv(prob_filepath, index=False)\n",
    "\n",
    "    # Ensemble\n",
    "    prob_df = pd.read_csv(\n",
    "        config.get_prob_filepath_from_checkpoint(config.checkpoint_paths[0])\n",
    "    )\n",
    "    if len(config.checkpoint_paths) > 1:\n",
    "        columns = BIRD_LIST\n",
    "        for checkpoint_path in config.checkpoint_paths[1:]:\n",
    "            _df = pd.read_csv(\n",
    "                config.get_prob_filepath_from_checkpoint(checkpoint_path)\n",
    "            )\n",
    "            prob_df[columns] += _df[columns]\n",
    "        prob_df[columns] /= len(config.checkpoint_paths)\n",
    "\n",
    "    return prob_df\n",
    "\n",
    "\n",
    "def seed_everything(seed=1234):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "\n",
    "def train(\n",
    "        candidate_df: pd.DataFrame,\n",
    "        df: pd.DataFrame,\n",
    "        candidate_df_soundscapes: pd.DataFrame,\n",
    "        df_soundscapes: pd.DataFrame,\n",
    "        num_kfolds: int,\n",
    "        num_candidates: int,\n",
    "        verbose: bool = False,\n",
    "        sampling_strategy: float = 1.0,\n",
    "        random_state: int = 777,\n",
    "):\n",
    "    seed_everything(random_state)\n",
    "    feature_names = get_feature_names()\n",
    "    if verbose:\n",
    "        print(\"features\", feature_names)\n",
    "\n",
    "    # short audio   k fold\n",
    "    groups = candidate_df[\"audio_id\"]\n",
    "    kf = StratifiedGroupKFold(\n",
    "        n_splits=num_kfolds)  # When using lgbm_rank, it is necessary to use the data attached to each group, so don't shuffle them.\n",
    "    for kfold_index, (_, valid_index) in enumerate(\n",
    "            kf.split(candidate_df[feature_names].values, candidate_df[\"target\"].values, groups)):\n",
    "        candidate_df.loc[valid_index, \"fold\"] = kfold_index\n",
    "\n",
    "    X = candidate_df[feature_names].values\n",
    "    y = candidate_df[\"target\"].values\n",
    "    oofa = np.zeros(len(candidate_df_soundscapes), dtype=np.float32)\n",
    "\n",
    "    for kfold_index in range(num_kfolds):\n",
    "        print(f\"fold {kfold_index}\")\n",
    "        train_index = candidate_df[candidate_df[\"fold\"] != kfold_index].index\n",
    "        valid_index = candidate_df[candidate_df[\"fold\"] == kfold_index].index\n",
    "        X_train, y_train = X[train_index], y[train_index]\n",
    "        #X_valid, y_valid = X[valid_index], y[valid_index]\n",
    "        X_valid, y_valid = candidate_df_soundscapes[feature_names].values, candidate_df_soundscapes[\"target\"].values\n",
    "\n",
    "        dtrain = lgb.Dataset(X_train, label=y_train)\n",
    "        dvalid = lgb.Dataset(X_valid, label=y_valid)\n",
    "        params = {\n",
    "            'objective': 'binary',\n",
    "            'metric': 'binary_logloss',\n",
    "            # 'device':'gpu', TODO change to GPU for cluster\n",
    "            'device': 'cpu'\n",
    "        }\n",
    "        model = lgb.train(\n",
    "            params,\n",
    "            dtrain,\n",
    "            valid_sets=dvalid,\n",
    "            num_boost_round=200,\n",
    "            early_stopping_rounds=20,\n",
    "            verbose_eval=20,\n",
    "        )\n",
    "        oofa += model.predict(X_valid.astype(np.float32)) / num_kfolds\n",
    "        pickle.dump(model, open(LGBM_PKL_DIR + f\"lgbm_{kfold_index}.pkl\", \"wb\"))\n",
    "\n",
    "    def f(th):\n",
    "        _df = candidate_df_soundscapes[(oofa > th)]\n",
    "        if len(_df) == 0:\n",
    "            return 0\n",
    "        _gdf = _df.groupby(\n",
    "            [\"audio_id\", \"seconds\"],\n",
    "            as_index=False\n",
    "        )[\"label\"].apply(lambda _: \" \".join(_))\n",
    "        df2 = pd.merge(\n",
    "            df_soundscapes[[\"audio_id\", \"seconds\", \"birds\"]],\n",
    "            _gdf,\n",
    "            how=\"left\",\n",
    "            on=[\"audio_id\", \"seconds\"]\n",
    "        )\n",
    "        df2.loc[df2[\"label\"].isnull(), \"label\"] = \"nocall\"\n",
    "        return df2.apply(\n",
    "            lambda _: get_metrics(_[\"birds\"], _[\"label\"])[\"f1\"],\n",
    "            axis=1\n",
    "        ).mean()\n",
    "\n",
    "    print(\"-\" * 30)\n",
    "    print(f\"#sound_scapes (len:{len(candidate_df_soundscapes)}) \")\n",
    "    lb, ub = 0, 1\n",
    "    for k in range(30):\n",
    "        th1 = (2 * lb + ub) / 3\n",
    "        th2 = (lb + 2 * ub) / 3\n",
    "        if f(th1) < f(th2):\n",
    "            lb = th1\n",
    "        else:\n",
    "            ub = th2\n",
    "    th = (lb + ub) / 2\n",
    "    print(\"best th: %.4f\" % th)\n",
    "    print(\"best F1: %.4f\" % f(th))\n",
    "    if verbose:\n",
    "        y_soundscapes = candidate_df_soundscapes[\"target\"].values\n",
    "        oof = (oofa > th).astype(int)\n",
    "        print(\"[details] Call or No call classirication\")\n",
    "        print(\"binary F1: %.4f\" % f1_score(y_soundscapes, oof))\n",
    "        print(\"gt positive ratio: %.4f\" % np.mean(y_soundscapes))\n",
    "        print(\"oof positive ratio: %.4f\" % np.mean(oof))\n",
    "        print(\"Accuracy: %.4f\" % accuracy_score(y_soundscapes, oof))\n",
    "        print(\"Recall: %.4f\" % recall_score(y_soundscapes, oof))\n",
    "        print(\"Precision: %.4f\" % precision_score(y_soundscapes, oof))\n",
    "    print(\"-\" * 30)\n",
    "    print()\n",
    "\n",
    "\n",
    "def get_feature_names() -> List[str]:\n",
    "    return [\n",
    "        \"year\",\n",
    "        \"month\",\n",
    "        \"sum_prob\",\n",
    "        \"mean_prob\",\n",
    "        #\"std_prob\",\n",
    "        \"max_prob\",\n",
    "        #\"min_prob\",\n",
    "        #\"skew_prob\",\n",
    "        #\"kurt_prob\",\n",
    "        \"prev6_prob\",\n",
    "        \"prev5_prob\",\n",
    "        \"prev4_prob\",\n",
    "        \"prev3_prob\",\n",
    "        \"prev2_prob\",\n",
    "        \"prev_prob\",\n",
    "        \"prob\",\n",
    "        \"next_prob\",\n",
    "        \"next2_prob\",\n",
    "        \"next3_prob\",\n",
    "        \"next4_prob\",\n",
    "        \"next5_prob\",\n",
    "        \"next6_prob\",\n",
    "        \"rank\",\n",
    "        \"latitude\",\n",
    "        \"longitude\",\n",
    "        \"bird_id\",  # +0.013700\n",
    "        \"seconds\",  # -0.0050\n",
    "        \"num_appear\",\n",
    "        \"site_num_appear\",\n",
    "        \"site_appear_ratio\",\n",
    "        # \"prob / num_appear\", # -0.005\n",
    "        # \"prob / site_num_appear\", # -0.0102\n",
    "        # \"prob * site_appear_ratio\", # -0.0049\n",
    "        # \"prob_avg\", # -0.0155\n",
    "        \"prob_diff\",  # 0.0082\n",
    "        # \"prob_avg_in_same_audio\", # -0.0256\n",
    "        # \"prob_max_in_same_audio\", # -0.0142\n",
    "        # \"prob_var_in_same_audio\", # -0.0304\n",
    "        # \"prob - prob_max_in_same_audio\", # -0.0069\n",
    "        # \"zscore_in_same_audio\", # -0.0110\n",
    "        # \"month_num_appear\", # 0.0164\n",
    "    ]\n",
    "\n",
    "\n",
    "def get_metrics(s_true, s_pred):\n",
    "    s_true = set(s_true.split())\n",
    "    s_pred = set(s_pred.split())\n",
    "    n, n_true, n_pred = len(s_true.intersection(s_pred)), len(s_true), len(s_pred)\n",
    "    prec = n / n_pred\n",
    "    rec = n / n_true\n",
    "    f1 = 2 * prec * rec / (prec + rec) if prec + rec else 0\n",
    "    return {\n",
    "        \"f1\": f1,\n",
    "        \"prec\": prec,\n",
    "        \"rec\": rec,\n",
    "        \"n_true\": n_true,\n",
    "        \"n_pred\": n_pred,\n",
    "        \"n\": n\n",
    "    }\n",
    "\n",
    "\n",
    "def optimize(\n",
    "        candidate_df: pd.DataFrame,\n",
    "        prob_df: pd.DataFrame,\n",
    "        num_kfolds: int,\n",
    "        weights_filepath_dict: dict,\n",
    "):\n",
    "    feature_names = get_feature_names()\n",
    "    X = candidate_df[feature_names].values\n",
    "    y_preda_list = []\n",
    "    for mode in weights_filepath_dict.keys():\n",
    "        fold_y_preda_list = []\n",
    "        for kfold_index in range(num_kfolds):\n",
    "            clf = pickle.load(open(weights_filepath_dict[mode][kfold_index], \"rb\"))\n",
    "            if mode == 'lgbm':\n",
    "                y_preda = clf.predict(X.astype(np.float32), num_iteration=clf.best_iteration)\n",
    "            elif mode == 'lgbm_rank':\n",
    "                y_preda = clf.predict(X.astype(np.float32), num_iteration=clf.best_iteration)\n",
    "            else:\n",
    "                y_preda = clf.predict_proba(X)[:, 1]\n",
    "            fold_y_preda_list.append(y_preda)\n",
    "        mean_preda = np.mean(fold_y_preda_list, axis=0)\n",
    "        if mode == 'lgbm_rank':  # scaling\n",
    "            mean_preda = 1 / (1 + np.exp(-mean_preda))\n",
    "        y_preda_list.append(mean_preda)\n",
    "    y_preda = np.mean(y_preda_list, axis=0)\n",
    "    candidate_df[\"y_preda\"] = y_preda\n",
    "\n",
    "    def f(th):\n",
    "        _df = candidate_df[y_preda > th]\n",
    "        if len(_df) == 0:\n",
    "            return 0\n",
    "        _gdf = _df.groupby(\n",
    "            [\"audio_id\", \"seconds\"],\n",
    "            as_index=False\n",
    "        )[\"label\"].apply(\n",
    "            lambda _: \" \".join(_)\n",
    "        ).rename(columns={\n",
    "            \"label\": \"predictions\"\n",
    "        })\n",
    "        submission_df = pd.merge(\n",
    "            prob_df[[\"row_id\", \"audio_id\", \"seconds\", \"birds\"]],\n",
    "            _gdf,\n",
    "            how=\"left\",\n",
    "            on=[\"audio_id\", \"seconds\"]\n",
    "        )\n",
    "        submission_df.loc[submission_df[\"predictions\"].isnull(), \"predictions\"] = \"nocall\"\n",
    "        return submission_df.apply(\n",
    "            lambda row: get_metrics(row[\"birds\"], row[\"predictions\"])[\"f1\"],\n",
    "            axis=1\n",
    "        ).mean()\n",
    "\n",
    "    lb, ub = 0, 1\n",
    "    for k in range(30):\n",
    "        th1 = (lb * 2 + ub) / 3\n",
    "        th2 = (lb + ub * 2) / 3\n",
    "        if f(th1) < f(th2):\n",
    "            lb = th1\n",
    "        else:\n",
    "            ub = th2\n",
    "    th = (lb + ub) / 2\n",
    "    print(\"-\" * 30)\n",
    "    print(\"best threshold: %f\" % th)\n",
    "    print(\"best F1: %f\" % f(th))\n",
    "\n",
    "    # nocall injection\n",
    "    _df = candidate_df[y_preda > th]\n",
    "    if len(_df) == 0:\n",
    "        return 0\n",
    "    _gdf = _df.groupby(\n",
    "        [\"audio_id\", \"seconds\"],\n",
    "        as_index=False\n",
    "    )[\"label\"].apply(\n",
    "        lambda _: \" \".join(_)\n",
    "    ).rename(columns={\n",
    "        \"label\": \"predictions\"\n",
    "    })\n",
    "    submission_df = pd.merge(\n",
    "        prob_df[[\"row_id\", \"audio_id\", \"seconds\", \"birds\"]],\n",
    "        _gdf,\n",
    "        how=\"left\",\n",
    "        on=[\"audio_id\", \"seconds\"]\n",
    "    )\n",
    "    submission_df.loc[submission_df[\"predictions\"].isnull(), \"predictions\"] = \"nocall\"\n",
    "\n",
    "    _gdf2 = _df.groupby(\n",
    "        [\"audio_id\", \"seconds\"],\n",
    "        as_index=False\n",
    "    )[\"y_preda\"].sum()\n",
    "    submission_df = pd.merge(\n",
    "        submission_df,\n",
    "        _gdf2,\n",
    "        how=\"left\",\n",
    "        on=[\"audio_id\", \"seconds\"]\n",
    "    )\n",
    "\n",
    "    def f_nocall(nocall_th):\n",
    "        submission_df_with_nocall = submission_df.copy()\n",
    "        submission_df_with_nocall.loc[(submission_df_with_nocall[\"y_preda\"] < nocall_th)\n",
    "                                      & (submission_df_with_nocall[\n",
    "                                             \"predictions\"] != \"nocall\"), \"predictions\"] += \" nocall\"\n",
    "        return submission_df_with_nocall.apply(\n",
    "            lambda row: get_metrics(row[\"birds\"], row[\"predictions\"])[\"f1\"],\n",
    "            axis=1\n",
    "        ).mean()\n",
    "\n",
    "    lb, ub = 0, 1\n",
    "    for k in range(30):\n",
    "        th1 = (lb * 2 + ub) / 3\n",
    "        th2 = (lb + ub * 2) / 3\n",
    "        if f_nocall(th1) < f_nocall(th2):\n",
    "            lb = th1\n",
    "        else:\n",
    "            ub = th2\n",
    "    nocall_th = (lb + ub) / 2\n",
    "    print(\"-\" * 30)\n",
    "    print(\"## nocall injection\")\n",
    "    print(\"best nocall threshold: %f\" % nocall_th)\n",
    "    print(\"best F1: %f\" % f_nocall(nocall_th))\n",
    "\n",
    "    return th, nocall_th\n",
    "\n",
    "\n",
    "def calc_baseline(prob_df: pd.DataFrame):\n",
    "    \"\"\"Calculate the optimal value of F1 score simply based on the threshold alone (without 3rd stage)\"\"\"\n",
    "    columns = BIRD_LIST\n",
    "    X = prob_df[columns].values\n",
    "\n",
    "    def f(th):\n",
    "        n = X.shape[0]\n",
    "        pred_labels = [[] for i in range(n)]\n",
    "        I, J = np.where(X > th)\n",
    "        for i, j in zip(I, J):\n",
    "            pred_labels[i].append(IDX2BIRD[j])\n",
    "        for i in range(n):\n",
    "            if len(pred_labels[i]) == 0:\n",
    "                pred_labels[i] = \"nocall\"\n",
    "            else:\n",
    "                pred_labels[i] = \" \".join(pred_labels[i])\n",
    "        prob_df[\"pred_labels\"] = pred_labels\n",
    "        return prob_df.apply(\n",
    "            lambda _: get_metrics(_[\"birds\"], _[\"pred_labels\"])[\"f1\"],\n",
    "            axis=1\n",
    "        ).mean()\n",
    "\n",
    "    lb, ub = 0, 1\n",
    "    for k in range(30):\n",
    "        th1 = (2 * lb + ub) / 3\n",
    "        th2 = (lb + 2 * ub) / 3\n",
    "        if f(th1) < f(th2):\n",
    "            lb = th1\n",
    "        else:\n",
    "            ub = th2\n",
    "    th = (lb + ub) / 2\n",
    "    print(\"best th: %.4f\" % th)\n",
    "    print(\"best F1: %.4f\" % f(th))\n",
    "    return th\n",
    "\n",
    "\n",
    "def make_submission(\n",
    "        candidate_df: pd.DataFrame,\n",
    "        prob_df: pd.DataFrame,\n",
    "        num_kfolds: int,\n",
    "        th: float,\n",
    "        nocall_th: float,\n",
    "        weights_filepath_dict: dict,\n",
    "        max_distance: int\n",
    "):\n",
    "    feature_names = get_feature_names()\n",
    "    X = candidate_df[feature_names].values\n",
    "    y_preda_list = []\n",
    "    for mode in weights_filepath_dict.keys():\n",
    "        fold_y_preda_list = []\n",
    "        for kfold_index in range(num_kfolds):\n",
    "            clf = pickle.load(open(weights_filepath_dict[mode][kfold_index], \"rb\"))\n",
    "            if mode == 'lgbm':\n",
    "                y_preda = clf.predict(X.astype(np.float32), num_iteration=clf.best_iteration)\n",
    "            elif mode == 'lgbm_rank':\n",
    "                y_preda = clf.predict(X.astype(np.float32), num_iteration=clf.best_iteration)\n",
    "            else:\n",
    "                y_preda = clf.predict_proba(X)[:, 1]\n",
    "            fold_y_preda_list.append(y_preda)\n",
    "        mean_preda = np.mean(fold_y_preda_list, axis=0)\n",
    "        if mode == 'lgbm_rank':  # scaling\n",
    "            mean_preda = 1 / (1 + np.exp(-mean_preda))\n",
    "        y_preda_list.append(mean_preda)\n",
    "    y_preda = np.mean(y_preda_list, axis=0)\n",
    "    candidate_df[\"y_preda\"] = y_preda\n",
    "\n",
    "    _df = candidate_df[y_preda > th]\n",
    "    _gdf = _df.groupby(\n",
    "        [\"audio_id\", \"seconds\"],\n",
    "        as_index=False\n",
    "    )[\"label\"].apply(\n",
    "        lambda _: \" \".join(_)\n",
    "    ).rename(columns={\n",
    "        \"label\": \"predictions\"\n",
    "    })\n",
    "    submission_df = pd.merge(\n",
    "        prob_df[[\"row_id\", \"audio_id\", \"seconds\", \"birds\"]],\n",
    "        _gdf,\n",
    "        how=\"left\",\n",
    "        on=[\"audio_id\", \"seconds\"]\n",
    "    )\n",
    "    submission_df.loc[submission_df[\"predictions\"].isnull(), \"predictions\"] = \"nocall\"\n",
    "    if TARGET_PATH:\n",
    "        score_df = pd.DataFrame(\n",
    "            submission_df.apply(\n",
    "                lambda row: get_metrics(row[\"birds\"], row[\"predictions\"]),\n",
    "                axis=1\n",
    "            ).tolist()\n",
    "        )\n",
    "        print(\"-\" * 30)\n",
    "        print(\"BEFORE nocall injection\")\n",
    "        print(\"CV score on a trained model with train_short_audio (to check the model behavior)\")\n",
    "        print(\"F1: %.4f\" % score_df[\"f1\"].mean())\n",
    "        print(\"Recall: %.4f\" % score_df[\"rec\"].mean())\n",
    "        print(\"Precision: %.4f\" % score_df[\"prec\"].mean())\n",
    "\n",
    "    # nocall injection\n",
    "    _gdf2 = _df.groupby(\n",
    "        [\"audio_id\", \"seconds\"],\n",
    "        as_index=False\n",
    "    )[\"y_preda\"].sum()\n",
    "    submission_df = pd.merge(\n",
    "        submission_df,\n",
    "        _gdf2,\n",
    "        how=\"left\",\n",
    "        on=[\"audio_id\", \"seconds\"]\n",
    "    )\n",
    "    submission_df.loc[(submission_df[\"y_preda\"] < nocall_th)\n",
    "                      & (submission_df[\"predictions\"] != \"nocall\"), \"predictions\"] += \" nocall\"\n",
    "    if TARGET_PATH:\n",
    "        score_df = pd.DataFrame(\n",
    "            submission_df.apply(\n",
    "                lambda row: get_metrics(row[\"birds\"], row[\"predictions\"]),\n",
    "                axis=1\n",
    "            ).tolist()\n",
    "        )\n",
    "        print(\"-\" * 30)\n",
    "        print(\"AFTER nocall injection\")\n",
    "        print(\"CV score on a trained model with train_short_audio (to check the model behavior)\")\n",
    "        print(\"F1: %.4f\" % score_df[\"f1\"].mean())\n",
    "        print(\"Recall: %.4f\" % score_df[\"rec\"].mean())\n",
    "        print(\"Precision: %.4f\" % score_df[\"prec\"].mean())\n",
    "\n",
    "    return submission_df[[\"row_id\", \"predictions\"]].rename(columns={\n",
    "        \"predictions\": \"birds\"\n",
    "    })\n",
    "\n",
    "\n",
    "####################################################\n",
    "# Train the model for the table competition part.\n",
    "####################################################\n",
    "\n",
    "TEST_AUDIO_ROOT = Path(\"../input/birdclef-2021/test_soundscapes\")\n",
    "SAMPLE_SUB_PATH = \"../input/birdclef-2021/sample_submission.csv\"\n",
    "TARGET_PATH = None\n",
    "\n",
    "if not len(\n",
    "        list(TEST_AUDIO_ROOT.glob(\"*.ogg\"))):  # If there isn't any sound source for testing, call for train_soundscapes\n",
    "    TEST_AUDIO_ROOT = Path(\"../input/birdclef-2021/train_soundscapes\")\n",
    "    SAMPLE_SUB_PATH = None\n",
    "    # SAMPLE_SUB_PATH = \"../input/birdclef-2021/sample_submission.csv\"\n",
    "    TARGET_PATH = Path(\"../input/birdclef-2021/train_soundscape_labels.csv\")\n",
    "\n",
    "# short audio\n",
    "# Exclude items that do not need to be trained\n",
    "if not \"site\" in prob_df.columns:\n",
    "    prob_df[\"site\"] = prob_df.apply(\n",
    "        lambda row: to_site(\n",
    "            row,\n",
    "            max_distance=training_config.max_distance\n",
    "        ),\n",
    "        axis=1\n",
    "    )\n",
    "    print(\"[exclude other]before: %d\" % len(prob_df))\n",
    "    prob_df = prob_df[prob_df[\"site\"] != \"Other\"].reset_index(drop=True)\n",
    "    print(\"[exclude other]after: %d\" % len(prob_df))\n",
    "\n",
    "candidate_df = make_candidates(\n",
    "    prob_df,\n",
    "    num_spieces=training_config.num_spieces,\n",
    "    num_candidates=training_config.num_candidates,\n",
    "    max_distance=training_config.max_distance\n",
    ")\n",
    "candidate_df = add_features(\n",
    "    candidate_df,\n",
    "    prob_df,\n",
    "    max_distance=training_config.max_distance\n",
    ")\n",
    "\n",
    "# soundscapes\n",
    "prob_df_soundscapes = get_prob_df(config, Path(\"../input/birdclef-2021/train_soundscapes\"))\n",
    "candidate_df_soundscapes = make_candidates(\n",
    "    prob_df_soundscapes,\n",
    "    num_spieces=training_config.num_spieces,\n",
    "    num_candidates=training_config.num_candidates,\n",
    "    max_distance=training_config.max_distance\n",
    ")\n",
    "candidate_df_soundscapes = add_features(\n",
    "    candidate_df_soundscapes,\n",
    "    prob_df_soundscapes,\n",
    "    max_distance=training_config.max_distance\n",
    ")\n",
    "\n",
    "for mode in config.weights_filepath_dict.keys():\n",
    "    print(f'training of {mode} is going...')\n",
    "    train(\n",
    "        candidate_df,\n",
    "        prob_df,\n",
    "        candidate_df_soundscapes,\n",
    "        prob_df_soundscapes,\n",
    "        num_kfolds=training_config.num_kfolds,\n",
    "        num_candidates=training_config.num_candidates,\n",
    "        verbose=True,\n",
    "    )\n",
    "\n",
    "######################################################\n",
    "# for submission\n",
    "######################################################\n",
    "prob_df = get_prob_df(config, TEST_AUDIO_ROOT)\n",
    "\n",
    "# candidate extraction\n",
    "candidate_df = make_candidates(\n",
    "    prob_df,\n",
    "    num_spieces=config.num_spieces,\n",
    "    num_candidates=config.num_candidates,\n",
    "    max_distance=config.max_distance,\n",
    "    num_prob=config.num_prob,\n",
    "    nocall_threshold=config.nocall_threshold\n",
    ")\n",
    "# add features\n",
    "candidate_df = add_features(\n",
    "    candidate_df,\n",
    "    prob_df,\n",
    "    max_distance=config.max_distance\n",
    ")\n",
    "\n",
    "if TARGET_PATH:\n",
    "    best_th, best_nocall_th = optimize(\n",
    "        candidate_df,\n",
    "        prob_df,\n",
    "        num_kfolds=config.num_kfolds,\n",
    "        weights_filepath_dict=config.weights_filepath_dict,\n",
    "    )\n",
    "if config.check_baseline:\n",
    "    print(\"-\" * 30)\n",
    "    print(\"check F1 score without 3rd stage(table competition)\")\n",
    "    calc_baseline(prob_df)\n",
    "\n",
    "submission_df = make_submission(\n",
    "    candidate_df,\n",
    "    prob_df,\n",
    "    num_kfolds=config.num_kfolds,\n",
    "    th=best_th,\n",
    "    nocall_th=best_nocall_th,\n",
    "    weights_filepath_dict=config.weights_filepath_dict,\n",
    "    max_distance=config.max_distance\n",
    ")\n",
    "\n",
    "submission_df.to_csv(\"../output/submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}