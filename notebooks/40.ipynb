{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-03T02:23:52.736634Z",
     "iopub.status.busy": "2021-06-03T02:23:52.736280Z",
     "iopub.status.idle": "2021-06-03T02:23:52.744879Z",
     "shell.execute_reply": "2021-06-03T02:23:52.744026Z",
     "shell.execute_reply.started": "2021-06-03T02:23:52.736595Z"
    },
    "id": "Q39ZsGAhVAqe",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "INPUT = Path('../input/')\n",
    "!pip install -q pysndfx SoundFile audiomentations pretrainedmodels efficientnet_pytorch resnest\n",
    "!pip install timm\n",
    "from typing import List\n",
    "import numpy as np\n",
    "import librosa as lb\n",
    "import librosa.display as lbd\n",
    "import soundfile as sf\n",
    "from soundfile import SoundFile\n",
    "import pandas as pd\n",
    "from IPython.display import Audio\n",
    "from pathlib import Path\n",
    "\n",
    "from pprint import pprint\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from resnest.torch import resnest50\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import timm\n",
    "import os, random, gc\n",
    "import re, time, json\n",
    "from ast import literal_eval\n",
    "\n",
    "from IPython.display import Audio\n",
    "from sklearn.metrics import label_ranking_average_precision_score\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "import joblib\n",
    "import glob\n",
    "\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "import pretrainedmodels\n",
    "import resnest.torch as resnest_torch\n",
    "\n",
    "!pip install../ input / scikit-learn-10dev0 / scikit_learn-1.0.dev0-cp37-cp37m-manylinux2010_x86_64.whl\n",
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "\n",
    "\n",
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "\n",
    "seed_everything()\n",
    "NUM_CLASSES = 397\n",
    "SR = 32_000\n",
    "DURATION = 7\n",
    "\n",
    "MAX_READ_SAMPLES = 10  # Each record will have 10 melspecs at most, you can increase this on Colab with High Memory Enabled\n",
    "\n",
    "\n",
    "class Config:\n",
    "    def __init__(self, debug: bool):\n",
    "        self.debug = debug\n",
    "\n",
    "        self.epochs = 1 if self.debug else 100  # 50\n",
    "\n",
    "        self.max_distance = None  # choose from [10, 20, None]\n",
    "        if self.max_distance is not None:\n",
    "            self.sites = [\"SSW\"]  # choose multiples from [\"COL\", \"COR\", \"SNE\", \"SSW\"]\n",
    "        else:\n",
    "            self.sites = None\n",
    "        self.max_duration = None  # choose from [15, 30, 60, None]\n",
    "        self.min_rating = None  # choose from [3, 4, None], best: 3?\n",
    "        self.max_spieces = None  # choose from [100, 200, 300, None], best: 300?\n",
    "        self.confidence_ub = 0.995  # Probability of birdsong occurrence, default: 0.995, choose from [0.5, 0.7, 0.9, 0.995]\n",
    "        self.use_high_confidence_only = False  # Whether to use only frames that are likely to be ringing (False performed better).\n",
    "        self.use_mixup = True\n",
    "        self.mixup_alpha = 0.5  # 5.0\n",
    "        self.secondary_labels_weight = 0.6  #0.6 > 0.8 > 0.3 for better performance\n",
    "        self.grouped_by_author = False\n",
    "        self.folds = [0, ]\n",
    "\n",
    "        self.use_weight = False\n",
    "        self.use_valid2020 = False\n",
    "        self.use_ff1010 = False\n",
    "\n",
    "        self.suffix = f\"_sr{SR}_d{DURATION}\"\n",
    "        if self.max_spieces:\n",
    "            self.suffix += f\"_spices-{self.max_spieces}\"\n",
    "        if self.min_rating:\n",
    "            self.suffix += f\"_rating-{self.min_rating}\"\n",
    "        if self.use_high_confidence_only:\n",
    "            self.suffix += f\"_high-confidence-only\"\n",
    "        if self.use_mixup:\n",
    "            self.suffix += f\"_miixup-{self.mixup_alpha}\"\n",
    "        if self.secondary_labels_weight:\n",
    "            self.suffix += f\"_2ndlw-{self.secondary_labels_weight}\"\n",
    "        if self.use_weight:\n",
    "            self.suffix += f\"_weight\"\n",
    "        if self.use_valid2020:\n",
    "            self.suffix += f\"_valid2020\"\n",
    "        if self.use_ff1010:\n",
    "            self.suffix += f\"_ff1010\"\n",
    "        if self.grouped_by_author:\n",
    "            self.suffix += f\"_grouped-by-auther\"\n",
    "\n",
    "    def to_dict(self):\n",
    "        return {\n",
    "            \"debug\": self.debug,\n",
    "            \"epochs\": self.epochs,\n",
    "            \"max_distance\": self.max_distance,\n",
    "            \"sites\": self.sites,\n",
    "            \"max_duration\": self.max_duration,\n",
    "            \"min_rating\": self.min_rating,\n",
    "            \"max_spieces\": self.max_spieces,\n",
    "            \"confidence_ub\": self.confidence_ub,\n",
    "            \"use_high_confidence_only\": self.use_high_confidence_only,\n",
    "            \"use_mixup\": self.use_mixup,\n",
    "            \"mixup_alpha\": self.mixup_alpha,\n",
    "            \"secondary_labels_weight\": self.secondary_labels_weight,\n",
    "            \"suffix\": self.suffix,\n",
    "            \"grouped_by_author\": self.grouped_by_author\n",
    "        }\n",
    "\n",
    "\n",
    "config = Config(debug=False)\n",
    "pprint(config.to_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-03T02:23:52.791850Z",
     "iopub.status.busy": "2021-06-03T02:23:52.791586Z",
     "iopub.status.idle": "2021-06-03T02:23:52.808929Z",
     "shell.execute_reply": "2021-06-03T02:23:52.808167Z",
     "shell.execute_reply.started": "2021-06-03T02:23:52.791821Z"
    },
    "id": "2NfkUn9SCWs6",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "MEL_PATHS = sorted(INPUT.glob(\"kkiller-birdclef-mels-computer-d7-part?/rich_train_metadata.csv\"))\n",
    "TRAIN_LABEL_PATHS = sorted(INPUT.glob(\"kkiller-birdclef-mels-computer-d7-part?/LABEL_IDS.json\"))\n",
    "MODEL_NAMES = [\n",
    "    # \"resnext101_32x8d_wsl\",\n",
    "    \"resnest50\",\n",
    "    # \"resnest26d\",\n",
    "    # \"tf_efficientnet_b0\",\n",
    "]\n",
    "MODEL_ROOT = Path(\".\")\n",
    "TRAIN_BATCH_SIZE = 64\n",
    "TRAIN_NUM_WORKERS = 2\n",
    "\n",
    "VAL_BATCH_SIZE = 64\n",
    "VAL_NUM_WORKERS = 2\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(\"Device:\", DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-03T02:23:52.820375Z",
     "iopub.status.busy": "2021-06-03T02:23:52.820030Z",
     "iopub.status.idle": "2021-06-03T02:23:52.827457Z",
     "shell.execute_reply": "2021-06-03T02:23:52.826372Z",
     "shell.execute_reply.started": "2021-06-03T02:23:52.820338Z"
    },
    "id": "9BcwFTpLp4CZ",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_df(mel_paths=MEL_PATHS, train_label_paths=TRAIN_LABEL_PATHS):\n",
    "    df = None\n",
    "    LABEL_IDS = {}\n",
    "\n",
    "    for file_path in mel_paths:\n",
    "        temp = pd.read_csv(str(file_path), index_col=0)\n",
    "        temp[\"impath\"] = temp.apply(\n",
    "            lambda row: file_path.parent / \"audio_images/{}/{}.npy\".format(row.primary_label, row.filename), axis=1)\n",
    "        df = temp if df is None else df.append(temp)\n",
    "\n",
    "    df[\"secondary_labels\"] = df[\"secondary_labels\"].apply(literal_eval)\n",
    "\n",
    "    for file_path in train_label_paths:\n",
    "        with open(str(file_path)) as f:\n",
    "            LABEL_IDS.update(json.load(f))\n",
    "\n",
    "    return LABEL_IDS, df\n",
    "\n",
    "\n",
    "def get_locations() -> List[dict]:\n",
    "    return [{\n",
    "        \"site\": \"COL\",\n",
    "        \"latitude\": 5.57,\n",
    "        \"longitude\": -75.85\n",
    "    }, {\n",
    "        \"site\": \"COR\",\n",
    "        \"latitude\": 10.12,\n",
    "        \"longitude\": -84.51\n",
    "    }, {\n",
    "        \"site\": \"SNE\",\n",
    "        \"latitude\": 38.49,\n",
    "        \"longitude\": -119.95\n",
    "    }, {\n",
    "        \"site\": \"SSW\",\n",
    "        \"latitude\": 42.47,\n",
    "        \"longitude\": -76.45\n",
    "    }]\n",
    "\n",
    "\n",
    "def is_in_site(row, sites, max_distance):\n",
    "    for location in get_locations():\n",
    "        if location[\"site\"] in sites:\n",
    "            x = (row[\"latitude\"] - location[\"latitude\"])\n",
    "            y = (row[\"longitude\"] - location[\"longitude\"])\n",
    "            r = (x ** 2 + y ** 2) ** 0.5\n",
    "            if r < max_distance:\n",
    "                return True\n",
    "    return False\n",
    "\n",
    "\n",
    "LABEL_IDS, df = get_df()\n",
    "\n",
    "if config.grouped_by_author:\n",
    "    kf = StratifiedGroupKFold(n_splits=5)\n",
    "    x = df[[\"latitude\", \"longitude\"]].values\n",
    "    y = df[\"label_id\"].values\n",
    "    groups = df[\"author\"].values\n",
    "    df[\"fold\"] = -1\n",
    "    for kfold_index, (train_index, valid_index) in enumerate(kf.split(x, y, groups)):\n",
    "        df.loc[valid_index, \"fold\"] = kfold_index\n",
    "\n",
    "if config.debug:\n",
    "    df = df.head(100)\n",
    "\n",
    "print(\"before:%d\" % len(df))\n",
    "# Within a certain distance of the target area\n",
    "if config.max_distance is not None:\n",
    "    df = df[df.apply(lambda row: is_in_site(row, config.sites, config.max_distance), axis=1)]\n",
    "# Number of Species\n",
    "if config.max_spieces is not None:\n",
    "    s = df[\"primary_label\"].value_counts().head(config.max_spieces)\n",
    "    df = df[df[\"primary_label\"].isin(s.index)]\n",
    "if config.min_rating is not None:\n",
    "    df = df[df[\"rating\"] >= config.min_rating]\n",
    "if config.max_duration is not None:\n",
    "    df = df[df[\"duration\"] < config.max_duration]\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-03T02:23:56.362725Z",
     "iopub.status.busy": "2021-06-03T02:23:56.362386Z",
     "iopub.status.idle": "2021-06-03T02:23:56.378481Z",
     "shell.execute_reply": "2021-06-03T02:23:56.377574Z",
     "shell.execute_reply.started": "2021-06-03T02:23:56.362687Z"
    },
    "id": "OGPDuihmVAqi",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_model(name, num_classes=NUM_CLASSES):\n",
    "    if \"resnest50\" in name:\n",
    "        if not os.path.exists(\"resnest50-528c19ca.pth\"):\n",
    "            !wget https: // github.com / rwightman / pytorch-image-models / releases / download / v0.1-resnest / resnest50-528c19ca.pth\n",
    "        pretrained_weights = torch.load('resnest50-528c19ca.pth')\n",
    "        model = getattr(resnest_torch, name)(pretrained=False)\n",
    "        model.load_state_dict(pretrained_weights)\n",
    "    elif \"resnest\" in name:\n",
    "        model = getattr(timm.models.resnest, name)(pretrained=True)\n",
    "    elif name.startswith(\"resnext\") or name.startswith(\"resnet\"):\n",
    "        model = torch.hub.load(\"pytorch/vision:v0.6.0\", name, pretrained=True)\n",
    "    elif \"wsl\" in name:\n",
    "        model = torch.hub.load(\"facebookresearch/WSL-Images\", name)\n",
    "    elif name.startswith(\"tf_efficientnet\"):\n",
    "        model = getattr(timm.models.efficientnet, name)(pretrained=True)\n",
    "    elif \"efficientnet-b\" in name:\n",
    "        model = EfficientNet.from_pretrained(name)\n",
    "    else:\n",
    "        model = pretrainedmodels.__dict__[name](pretrained='imagenet')\n",
    "\n",
    "    if hasattr(model, \"fc\"):\n",
    "        nb_ft = model.fc.in_features\n",
    "        model.fc = nn.Linear(nb_ft, num_classes)\n",
    "    elif hasattr(model, \"_fc\"):\n",
    "        nb_ft = model._fc.in_features\n",
    "        model._fc = nn.Linear(nb_ft, num_classes)\n",
    "    elif hasattr(model, \"classifier\"):\n",
    "        nb_ft = model.classifier.in_features\n",
    "        model.classifier = nn.Linear(nb_ft, num_classes)\n",
    "    elif hasattr(model, \"last_linear\"):\n",
    "        nb_ft = model.last_linear.in_features\n",
    "        model.last_linear = nn.Linear(nb_ft, num_classes)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ucm8kz8d0qjp",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## nocall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-03T02:23:56.381220Z",
     "iopub.status.busy": "2021-06-03T02:23:56.380262Z",
     "iopub.status.idle": "2021-06-03T02:24:03.552074Z",
     "shell.execute_reply": "2021-06-03T02:24:03.551201Z",
     "shell.execute_reply.started": "2021-06-03T02:23:56.381175Z"
    },
    "id": "Tyexj-2kzgcD",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "nocall_paths = glob.glob(\"../input/train-short-audio-nocall-fold0to4/train_short_audio_nocall_fold0to4/*.csv\")\n",
    "probs_list = []\n",
    "for nocall_path in nocall_paths:\n",
    "    nocall_df = pd.read_csv(nocall_path)\n",
    "    probs = nocall_df[\"nocalldetection\"].apply(\n",
    "        lambda _: list(\n",
    "            map(\n",
    "                float,\n",
    "                _.split()\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    probs_list.append(probs)\n",
    "probs = []\n",
    "for di in range(len(nocall_df)):\n",
    "    one_row = []\n",
    "    for ni in range(len(nocall_paths)):\n",
    "        one_row.append(probs_list[ni][di])\n",
    "    probs.append(np.mean(one_row, axis=0).tolist())\n",
    "\n",
    "audio_prob_store = dict(zip(nocall_df[\"filename\"].tolist(), probs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gz735EP20s7B",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## valid2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-03T02:24:03.553783Z",
     "iopub.status.busy": "2021-06-03T02:24:03.553445Z",
     "iopub.status.idle": "2021-06-03T02:24:03.560672Z",
     "shell.execute_reply": "2021-06-03T02:24:03.559666Z",
     "shell.execute_reply.started": "2021-06-03T02:24:03.553747Z"
    },
    "id": "uXiejdY9tNGE",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "if config.use_valid2020:\n",
    "    clef_2020_df = pd.read_csv(\"../input/birdclef2020-validation-audio-and-ground-truth-d5/rich_metadata.csv\",\n",
    "                               index_col=0)\n",
    "    clef_2020_df[\"fold\"] = clef_2020_df[\"file_fold\"] % 5\n",
    "    clef_2020_df[\"impath\"] = \"../input/birdclef2020-validation-audio-and-ground-truth-d5/\" + clef_2020_df[\n",
    "        \"primary_label\"] + \"/\" + clef_2020_df[\"filename\"] + \".npy\"\n",
    "    clef_2020_df[\"label_id\"] = -1\n",
    "    clef_2020_df = clef_2020_df[clef_2020_df[\"primary_label\"] == \"nocall\"]\n",
    "    clef_2020_df[\"secondary_labels\"] = [[] for i in range(len(clef_2020_df))]\n",
    "\n",
    "    # Update prob with nocall detector\n",
    "    probs = [[0] for i in range(len(clef_2020_df))]\n",
    "    prob_dict = dict(zip(clef_2020_df[\"filename\"].tolist(), probs))\n",
    "    audio_prob_store.update(prob_dict)\n",
    "\n",
    "    df = pd.concat([clef_2020_df, df]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QaLMP9Ag21yP",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# ff1010"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-03T02:24:03.562795Z",
     "iopub.status.busy": "2021-06-03T02:24:03.562143Z",
     "iopub.status.idle": "2021-06-03T02:24:03.572344Z",
     "shell.execute_reply": "2021-06-03T02:24:03.571489Z",
     "shell.execute_reply.started": "2021-06-03T02:24:03.562758Z"
    },
    "id": "opK713Pt26m5",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "if config.use_ff1010:\n",
    "    #!unzip -q /content/drive/MyDrive/git/kaggle-birdclef-2021/working/preprocessed/ff1010bird_duration7.zip -d {INPUT}/ff1010bird_duration7\n",
    "\n",
    "    ff1010_df = pd.read_csv(\"../input/ff1010bird-duration7-1/rich_metadata.csv\", index_col=0)\n",
    "    ff1010_df[\"impath\"] = \"../input/ff1010bird-duration7-1/\" + ff1010_df[\"primary_label\"] + \"/\" + ff1010_df[\n",
    "        \"filename\"] + \".npy\"\n",
    "    ff1010_df = ff1010_df[ff1010_df[\"primary_label\"] == \"nocall\"]  #nocall のみを使う\n",
    "    ff1010_df[\"label_id\"] = -1\n",
    "    ff1010_df[\"fold\"] = ff1010_df.index % 5\n",
    "    ff1010_df[\"secondary_labels\"] = [[] for i in range(len(ff1010_df))]\n",
    "\n",
    "    # Update prob with nocall detector\n",
    "    probs = [[0] for i in range(len(ff1010_df))]\n",
    "    prob_dict = dict(zip(ff1010_df[\"filename\"].tolist(), probs))\n",
    "    audio_prob_store.update(prob_dict)\n",
    "\n",
    "    df = pd.concat([ff1010_df, df]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-03T02:24:05.028119Z",
     "iopub.status.busy": "2021-06-03T02:24:05.027698Z",
     "iopub.status.idle": "2021-06-03T02:24:05.045729Z",
     "shell.execute_reply": "2021-06-03T02:24:05.044793Z",
     "shell.execute_reply.started": "2021-06-03T02:24:05.028080Z"
    },
    "id": "OWSkCXyhCWs-",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def load_data(df):\n",
    "    def load_row(row):\n",
    "        # impath = TRAIN_IMAGES_ROOT/f\"{row.primary_label}/{row.filename}.npy\"\n",
    "        return row.filename, np.load(str(row.impath))[:MAX_READ_SAMPLES]\n",
    "\n",
    "    pool = joblib.Parallel(4)\n",
    "    mapper = joblib.delayed(load_row)\n",
    "    tasks = [mapper(row) for row in df.itertuples(False)]\n",
    "    res = pool(tqdm(tasks))\n",
    "    res = dict(res)\n",
    "    return res\n",
    "\n",
    "\n",
    "audio_image_store = load_data(df)\n",
    "\n",
    "image_w = 281\n",
    "\n",
    "\n",
    "def pad_image(image, image_w=image_w):\n",
    "    h = image.shape[0]\n",
    "    w = image.shape[1]\n",
    "    if w < image_w:\n",
    "        start = np.random.choice((image_w - w))\n",
    "        ret = np.zeros((h, image_w))\n",
    "        ret[:, start:start + w] = image\n",
    "        return ret\n",
    "    return image\n",
    "\n",
    "\n",
    "class BirdClefDataset(Dataset):\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            audio_image_store,\n",
    "            audio_prob_store,\n",
    "            meta,\n",
    "            sr=SR,\n",
    "            is_train=True,\n",
    "            num_classes=NUM_CLASSES,\n",
    "            duration=DURATION,\n",
    "    ):\n",
    "        self.audio_image_store = audio_image_store\n",
    "        self.audio_prob_store = audio_prob_store\n",
    "        self.meta = meta.copy().reset_index(drop=True)\n",
    "        self.sr = sr\n",
    "        self.is_train = is_train\n",
    "        self.num_classes = num_classes\n",
    "        self.duration = duration\n",
    "        self.audio_length = self.duration * self.sr\n",
    "        self.eps = 0.0025\n",
    "\n",
    "    @staticmethod\n",
    "    def normalize(image):\n",
    "        image = image.astype(\"float32\", copy=False) / 255.0\n",
    "        image = np.stack([image, image, image])\n",
    "        return image\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.meta)\n",
    "\n",
    "    def mixup_data(self, image, noize, alpha=0.5):\n",
    "        if alpha > 0.:\n",
    "            lam = np.random.beta(alpha, alpha)\n",
    "        else:\n",
    "            lam = 1.\n",
    "        lam /= 2  # leave it at half maximum.\n",
    "        mixed_x = (1 - lam) * image + lam * noize\n",
    "        return mixed_x\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.meta.iloc[idx]\n",
    "        images = self.audio_image_store[row.filename]\n",
    "        probs = self.audio_prob_store[row.filename]\n",
    "\n",
    "        i = np.random.choice(len(images))\n",
    "        image = images[i]\n",
    "\n",
    "        if image.shape[1] < self.audio_length:\n",
    "            image = pad_image(image, image_w)\n",
    "\n",
    "        image = self.normalize(image)\n",
    "        prob = probs[i]\n",
    "        t = np.zeros(self.num_classes, dtype=np.float32) + self.eps  # Label smoothing\n",
    "        t[row.label_id] = max(min(prob, config.confidence_ub), self.eps)  # clipping\n",
    "        for secondary_label in row.secondary_labels:\n",
    "            # Set a lower value than the primary label\n",
    "            if secondary_label in LABEL_IDS:\n",
    "                t[LABEL_IDS[secondary_label]] = max(self.eps, prob * 0.6)\n",
    "\n",
    "        return image, t\n",
    "\n",
    "\n",
    "ds = BirdClefDataset(audio_image_store, audio_prob_store, meta=df, sr=SR, duration=DURATION, is_train=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F56zXq8CVAqn",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-03T02:24:05.202166Z",
     "iopub.status.busy": "2021-06-03T02:24:05.201765Z",
     "iopub.status.idle": "2021-06-03T02:24:05.208153Z",
     "shell.execute_reply": "2021-06-03T02:24:05.207228Z",
     "shell.execute_reply.started": "2021-06-03T02:24:05.202129Z"
    },
    "id": "THm438BwMTeR",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def mixup_data(x, y, alpha=0.5, use_cuda=True):\n",
    "    if alpha > 0.:\n",
    "        lam = np.random.beta(alpha, alpha)\n",
    "    else:\n",
    "        lam = 1.\n",
    "    batch_size = x.size()[0]\n",
    "    if use_cuda:\n",
    "        index = torch.randperm(batch_size).cuda()\n",
    "    else:\n",
    "        index = torch.randperm(batch_size)\n",
    "\n",
    "    mixed_x = lam * x + (1 - lam) * x[index, :]\n",
    "    mixed_y = lam * y + (1 - lam) * y[index]\n",
    "    #mixed_y = torch.maximum(y, y[index])\n",
    "    return mixed_x, mixed_y, lam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-03T02:24:05.210435Z",
     "iopub.status.busy": "2021-06-03T02:24:05.209874Z",
     "iopub.status.idle": "2021-06-03T02:24:05.221265Z",
     "shell.execute_reply": "2021-06-03T02:24:05.220342Z",
     "shell.execute_reply.started": "2021-06-03T02:24:05.210394Z"
    },
    "id": "9Kjy1uquIGZw",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def one_step(xb, yb, net, criterion, optimizer, scheduler=None):\n",
    "    if config.use_mixup:\n",
    "        xb, yb, lam = mixup_data(xb, yb, alpha=config.mixup_alpha)\n",
    "    xb, yb = xb.to(DEVICE), yb.to(DEVICE)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    o = net(xb)\n",
    "    loss = criterion(o, yb)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        l = loss.item()\n",
    "\n",
    "        o = o.sigmoid()\n",
    "        yb = (yb > 0.5) * 1.0\n",
    "        lrap = label_ranking_average_precision_score(yb.cpu().numpy(), o.cpu().numpy())\n",
    "\n",
    "        o = (o > 0.5) * 1.0\n",
    "\n",
    "        prec = (o * yb).sum() / (1e-6 + o.sum())\n",
    "        rec = (o * yb).sum() / (1e-6 + yb.sum())\n",
    "        f1 = 2 * prec * rec / (1e-6 + prec + rec)\n",
    "\n",
    "    if scheduler is not None:\n",
    "        scheduler.step()\n",
    "\n",
    "    return l, lrap, f1.item(), rec.item(), prec.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-03T02:24:05.223155Z",
     "iopub.status.busy": "2021-06-03T02:24:05.222592Z",
     "iopub.status.idle": "2021-06-03T02:24:05.233851Z",
     "shell.execute_reply": "2021-06-03T02:24:05.232925Z",
     "shell.execute_reply.started": "2021-06-03T02:24:05.223112Z"
    },
    "id": "q9v79J0pvXy1",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate(net, criterion, val_laoder):\n",
    "    net.eval()\n",
    "\n",
    "    os, y = [], []\n",
    "    val_laoder = tqdm(val_laoder, leave=False, total=len(val_laoder))\n",
    "\n",
    "    for icount, (xb, yb) in enumerate(val_laoder):\n",
    "        y.append(yb.to(DEVICE))\n",
    "\n",
    "        xb = xb.to(DEVICE)\n",
    "        o = net(xb)\n",
    "\n",
    "        os.append(o)\n",
    "\n",
    "    y = torch.cat(y)\n",
    "    o = torch.cat(os)\n",
    "\n",
    "    l = criterion(o, y).item()\n",
    "\n",
    "    o = o.sigmoid()\n",
    "    y = (y > 0.5) * 1.0\n",
    "\n",
    "    lrap = label_ranking_average_precision_score(y.cpu().numpy(), o.cpu().numpy())\n",
    "\n",
    "    o = (o > 0.5) * 1.0\n",
    "    # Kyle: calculating the precision and recall and then the F1 score\n",
    "    prec = ((o * y).sum() / (1e-6 + o.sum())).item()\n",
    "    rec = ((o * y).sum() / (1e-6 + y.sum())).item()\n",
    "    f1 = 2 * prec * rec / (1e-6 + prec + rec)\n",
    "\n",
    "    return l, lrap, f1, rec, prec,\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-03T02:24:05.235553Z",
     "iopub.status.busy": "2021-06-03T02:24:05.235038Z",
     "iopub.status.idle": "2021-06-03T02:24:05.250393Z",
     "shell.execute_reply": "2021-06-03T02:24:05.249558Z",
     "shell.execute_reply.started": "2021-06-03T02:24:05.235513Z"
    },
    "id": "qeDgf4LdLWGN",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def one_epoch(net, criterion, optimizer, scheduler, train_laoder, val_laoder):\n",
    "    net.train()\n",
    "    l, lrap, prec, rec, f1, icount = 0., 0., 0., 0., 0., 0\n",
    "    train_laoder = tqdm(train_laoder, leave=False)\n",
    "    epoch_bar = train_laoder\n",
    "\n",
    "    for (xb, yb) in epoch_bar:\n",
    "        # epoch_bar.set_description(\"----|----|----|----|---->\")\n",
    "        _l, _lrap, _f1, _rec, _prec = one_step(xb, yb, net, criterion, optimizer)\n",
    "        l += _l\n",
    "        lrap += _lrap\n",
    "        f1 += _f1\n",
    "        rec += _rec\n",
    "        prec += _prec\n",
    "\n",
    "        icount += 1\n",
    "\n",
    "        if hasattr(epoch_bar, \"set_postfix\") and not icount % 10:\n",
    "            epoch_bar.set_postfix(\n",
    "                loss=\"{:.6f}\".format(l / icount),\n",
    "                lrap=\"{:.3f}\".format(lrap / icount),\n",
    "                prec=\"{:.3f}\".format(prec / icount),\n",
    "                rec=\"{:.3f}\".format(rec / icount),\n",
    "                f1=\"{:.3f}\".format(f1 / icount),\n",
    "            )\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "    l /= icount\n",
    "    lrap /= icount\n",
    "    f1 /= icount\n",
    "    rec /= icount\n",
    "    prec /= icount\n",
    "\n",
    "    l_val, lrap_val, f1_val, rec_val, prec_val = evaluate(net, criterion, val_laoder)\n",
    "\n",
    "    return (l, l_val), (lrap, lrap_val), (f1, f1_val), (rec, rec_val), (prec, prec_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-03T02:24:05.252222Z",
     "iopub.status.busy": "2021-06-03T02:24:05.251682Z",
     "iopub.status.idle": "2021-06-03T02:24:05.267027Z",
     "shell.execute_reply": "2021-06-03T02:24:05.265873Z",
     "shell.execute_reply.started": "2021-06-03T02:24:05.252157Z"
    },
    "id": "Cz7XPBvtPLO1",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class AutoSave:\n",
    "    def __init__(self, top_k=50, metric=\"f1\", mode=\"min\", root=None, name=\"ckpt\"):\n",
    "        self.top_k = top_k\n",
    "        self.logs = []\n",
    "        self.metric = metric\n",
    "        self.mode = mode\n",
    "        self.root = Path(root or MODEL_ROOT)\n",
    "        assert self.root.exists()\n",
    "        self.name = name\n",
    "\n",
    "        self.top_models = []\n",
    "        self.top_metrics = []\n",
    "\n",
    "    def log(self, model, metrics):\n",
    "        metric = metrics[self.metric]\n",
    "        rank = self.rank(metric)\n",
    "\n",
    "        self.top_metrics.insert(rank + 1, metric)\n",
    "        if len(self.top_metrics) > self.top_k:\n",
    "            self.top_metrics.pop(0)\n",
    "\n",
    "        self.logs.append(metrics)\n",
    "        self.save(model, metric, rank, metrics[\"epoch\"])\n",
    "\n",
    "    def save(self, model, metric, rank, epoch):\n",
    "        t = time.strftime(\"%Y%m%d%H%M%S\")\n",
    "        name = \"{}_epoch_{:02d}_{}_{:.04f}_{}\".format(self.name, epoch, self.metric, metric, t)\n",
    "        name = re.sub(r\"[^\\w_-]\", \"\", name) + \".pth\"\n",
    "        path = self.root.joinpath(name)\n",
    "\n",
    "        old_model = None\n",
    "        self.top_models.insert(rank + 1, name)\n",
    "        if len(self.top_models) > self.top_k:\n",
    "            old_model = self.root.joinpath(self.top_models[0])\n",
    "            self.top_models.pop(0)\n",
    "\n",
    "        torch.save(model.state_dict(), path.as_posix())\n",
    "\n",
    "        if old_model is not None:\n",
    "            old_model.unlink()\n",
    "\n",
    "        self.to_json()\n",
    "\n",
    "    def rank(self, val):\n",
    "        r = -1\n",
    "        for top_val in self.top_metrics:\n",
    "            if val <= top_val:\n",
    "                return r\n",
    "            r += 1\n",
    "\n",
    "        return r\n",
    "\n",
    "    def to_json(self):\n",
    "        # t = time.strftime(\"%Y%m%d%H%M%S\")\n",
    "        name = \"{}_logs\".format(self.name)\n",
    "        name = re.sub(r\"[^\\w_-]\", \"\", name) + \".json\"\n",
    "        path = self.root.joinpath(name)\n",
    "\n",
    "        with path.open(\"w\") as f:\n",
    "            json.dump(self.logs, f, indent=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-03T02:24:05.269095Z",
     "iopub.status.busy": "2021-06-03T02:24:05.268390Z",
     "iopub.status.idle": "2021-06-03T02:24:05.287742Z",
     "shell.execute_reply": "2021-06-03T02:24:05.286876Z",
     "shell.execute_reply.started": "2021-06-03T02:24:05.269056Z"
    },
    "id": "8X1dt_aWNi6F",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def one_fold(model_name, fold, train_set, val_set, epochs=20, save=True, save_root=None):\n",
    "    save_root = Path(save_root) or MODEL_ROOT\n",
    "\n",
    "    saver = AutoSave(root=save_root, name=f\"birdclef_{model_name}_fold{fold}\", metric=\"f1_val\")\n",
    "\n",
    "    net = get_model(model_name).to(DEVICE)\n",
    "\n",
    "    #criterion = nn.BCEWithLogitsLoss()\n",
    "    weight = None\n",
    "    if config.use_weight:\n",
    "        label_inv = (1 / df[\"label_id\"].value_counts().sort_index()).values\n",
    "        label_inv_mean = label_inv.mean()\n",
    "        weight = label_inv * (1 / label_inv_mean)  # Inverse proportion such that the mean is 1\n",
    "        weight = torch.tensor(weight).to(DEVICE)\n",
    "    criterion = nn.BCEWithLogitsLoss(weight=weight)\n",
    "\n",
    "    lr = 8e-4\n",
    "    optimizer = optim.Adam(net.parameters(), lr=lr)\n",
    "    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, eta_min=1e-5, T_max=epochs)\n",
    "\n",
    "    train_data = BirdClefDataset(\n",
    "        audio_image_store,\n",
    "        audio_prob_store,\n",
    "        meta=df.iloc[train_set].reset_index(drop=True),\n",
    "        sr=SR,\n",
    "        duration=DURATION,\n",
    "        is_train=True\n",
    "    )\n",
    "    train_laoder = DataLoader(train_data, batch_size=TRAIN_BATCH_SIZE, num_workers=TRAIN_NUM_WORKERS, shuffle=True,\n",
    "                              pin_memory=True)\n",
    "\n",
    "    val_data = BirdClefDataset(\n",
    "        audio_image_store,\n",
    "        audio_prob_store,\n",
    "        meta=df.iloc[val_set].reset_index(drop=True),\n",
    "        sr=SR,\n",
    "        duration=DURATION,\n",
    "        is_train=False)\n",
    "    val_laoder = DataLoader(val_data, batch_size=VAL_BATCH_SIZE, num_workers=VAL_NUM_WORKERS, shuffle=False)\n",
    "\n",
    "    epochs_bar = tqdm(list(range(epochs)), leave=False)\n",
    "    for epoch in epochs_bar:\n",
    "        epochs_bar.set_description(f\"--> [EPOCH {epoch:02d}]\")\n",
    "        net.train()\n",
    "\n",
    "        (l, l_val), (lrap, lrap_val), (f1, f1_val), (rec, rec_val), (prec, prec_val) = one_epoch(\n",
    "            net=net,\n",
    "            criterion=criterion,\n",
    "            optimizer=optimizer,\n",
    "            scheduler=scheduler,\n",
    "            train_laoder=train_laoder,\n",
    "            val_laoder=val_laoder,\n",
    "        )\n",
    "\n",
    "        epochs_bar.set_postfix(\n",
    "            loss=\"({:.6f}, {:.6f})\".format(l, l_val),\n",
    "            prec=\"({:.3f}, {:.3f})\".format(prec, prec_val),\n",
    "            rec=\"({:.3f}, {:.3f})\".format(rec, rec_val),\n",
    "            f1=\"({:.3f}, {:.3f})\".format(f1, f1_val),\n",
    "            lrap=\"({:.3f}, {:.3f})\".format(lrap, lrap_val),\n",
    "        )\n",
    "\n",
    "        print(\n",
    "            \"[{epoch:02d}] loss: {loss} lrap: {lrap} f1: {f1} rec: {rec} prec: {prec}\".format(\n",
    "                epoch=epoch,\n",
    "                loss=\"({:.6f}, {:.6f})\".format(l, l_val),\n",
    "                prec=\"({:.3f}, {:.3f})\".format(prec, prec_val),\n",
    "                rec=\"({:.3f}, {:.3f})\".format(rec, rec_val),\n",
    "                f1=\"({:.3f}, {:.3f})\".format(f1, f1_val),\n",
    "                lrap=\"({:.3f}, {:.3f})\".format(lrap, lrap_val),\n",
    "            )\n",
    "        )\n",
    "\n",
    "        if save:\n",
    "            metrics = {\n",
    "                \"loss\": l, \"lrap\": lrap, \"f1\": f1, \"rec\": rec, \"prec\": prec,\n",
    "                \"loss_val\": l_val, \"lrap_val\": lrap_val, \"f1_val\": f1_val, \"rec_val\": rec_val, \"prec_val\": prec_val,\n",
    "                \"epoch\": epoch,\n",
    "            }\n",
    "\n",
    "            saver.log(net, metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-03T02:24:05.289734Z",
     "iopub.status.busy": "2021-06-03T02:24:05.289047Z",
     "iopub.status.idle": "2021-06-03T02:24:05.298574Z",
     "shell.execute_reply": "2021-06-03T02:24:05.297653Z",
     "shell.execute_reply.started": "2021-06-03T02:24:05.289695Z"
    },
    "id": "ljqr4e2zQmzB",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def train(model_name, epochs=20, save=True, n_splits=5, seed=177, save_root=None, suffix=\"\", folds=None):\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    save_root = save_root or MODEL_ROOT / f\"{model_name}{suffix}\"\n",
    "    save_root.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "    fold_bar = tqdm(df.reset_index().groupby(\"fold\").index.apply(list).items(), total=df.fold.max() + 1)\n",
    "\n",
    "    for fold, val_set in fold_bar:\n",
    "        if folds and not fold in folds:\n",
    "            continue\n",
    "\n",
    "        print(f\"\\n############################### [FOLD {fold}]\")\n",
    "        fold_bar.set_description(f\"[FOLD {fold}]\")\n",
    "        train_set = np.setdiff1d(df.index, val_set)\n",
    "\n",
    "        one_fold(model_name, fold=fold, train_set=train_set, val_set=val_set, epochs=epochs, save=save,\n",
    "                 save_root=save_root)\n",
    "\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "\n",
    "for model_name in MODEL_NAMES:\n",
    "    print(\"\\n\\n###########################################\", model_name.upper())\n",
    "    train(model_name, epochs=config.epochs, suffix=config.suffix, folds=config.folds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}